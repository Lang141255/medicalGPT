{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "pn2zMFivHkWJ"
      },
      "source": [
        "# Training Pipeline\n",
        "[run_training_pipeline.ipynb](https://github.com/shibing624/MedicalGPT/blob/main/run_training_pipeline.ipynb)    | [Open In Colab](https://colab.research.google.com/github/shibing624/MedicalGPT/blob/main/run_training_pipeline.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "62AmjoGOHkWK"
      },
      "source": [
        "# Stage 1: Continue Pretraining\n",
        "\n",
        "第一阶段：PT(Continue PreTraining)增量预训练，在海量领域文本数据上二次预训练GPT模型，以适配领域数据分布\n",
        "\n",
        "注意：\n",
        "1. 此阶段是可选的，如果你没有海量领域文本，可以跳过此阶段，直接进行SFT阶段的有监督微调\n",
        "2. 我实验发现：做领域知识注入，SFT比PT更高效，也可以跳过PT阶段\n",
        "\n",
        "| Stage 1: Continue Pretraining   |  [pretraining.py](https://github.com/shibing624/MedicalGPT/blob/main/pretraining.py) | [run_pt.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_pt.sh)    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZGGLRGjHkWL"
      },
      "source": [
        "#### 说明：\n",
        "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
        "\n",
        "1. 生成模型：使用的是Qwen/Qwen2.5-0.5B\n",
        "2. 数据集：PT阶段使用的是中文天龙八部小说部分文本和英文书籍部分文本，位于`data/pretrain`文件夹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjUnJgSXHkWL"
      },
      "source": [
        "## 配置运行环境\n",
        "\n",
        "本地执行可注释以下配置环境的命令，colab执行要打开注释，用于配置环境\n",
        "\n",
        "colab建议使用T4 GPU训练，设置方式：`代码执行程序 -> 更改运行时类型 -> 运行时类型：Python3，硬件加速器：GPU，GPU类型：T4 -> 保存`\n",
        "\n",
        "步骤：\n",
        "1. 下载最新代码到本地\n",
        "2. 安装依赖包\n",
        "\n",
        "依赖包如下，保证最新版本：\n",
        "\n",
        "```\n",
        "loguru\n",
        "transformers\n",
        "sentencepiece\n",
        "datasets\n",
        "tensorboard\n",
        "tqdm\n",
        "peft\n",
        "trl\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y-wU0wqXHkWL",
        "outputId": "3350f12f-01b6-44c1-fca0-f634e83a3ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MedicalGPT'...\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 98 (delta 19), reused 52 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (98/98), 8.98 MiB | 16.36 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n",
            "/content/MedicalGPT\n",
            "build_domain_tokenizer.py   requirements.txt\n",
            "chatpdf.py                  reward_modeling.py\n",
            "CITATION.cff                \u001b[0m\u001b[01;34mrole_play_data\u001b[0m/\n",
            "_config.yml                 run_dpo.sh\n",
            "CONTRIBUTING.md             run_eval_quantize.sh\n",
            "convert_dataset.py          run_full_sft.sh\n",
            "\u001b[01;34mdata\u001b[0m/                       run_grpo.sh\n",
            "DISCLAIMER                  run_orpo.sh\n",
            "\u001b[01;34mdocs\u001b[0m/                       run_ppo.sh\n",
            "dpo_training.py             run_pt.sh\n",
            "eval_quantize.py            run_quant.sh\n",
            "fastapi_server_demo.py      run_rm.sh\n",
            "gradio_demo.py              run_sft_accelerate.sh\n",
            "grpo_training.py            run_sft.sh\n",
            "inference_multigpu_demo.py  run_training_dpo_pipeline.ipynb\n",
            "inference.py                run_training_ppo_pipeline.ipynb\n",
            "LICENSE                     supervised_finetuning_accelerate.py\n",
            "merge_peft_adapter.py       supervised_finetuning.py\n",
            "merge_tokenizers.py         template.py\n",
            "model_quant.py              validate_jsonl.py\n",
            "openai_api.py               vllm_deployment.sh\n",
            "orpo_training.py            zero1.yaml\n",
            "ppo_training.py             zero2.json\n",
            "pretraining.py              zero2.yaml\n",
            "README_EN.md                zero3.json\n",
            "README.md                   zero3.yaml\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: datasets>=2.14.6 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (4.0.0)\n",
            "Collecting loguru (from -r requirements.txt (line 3))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: peft>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (0.18.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.19.0)\n",
            "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.49.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.57.3)\n",
            "Collecting trl>=0.15.2 (from -r requirements.txt (line 10))\n",
            "  Downloading trl-0.26.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting latex2sympy2_extended (from -r requirements.txt (line 12))\n",
            "  Downloading latex2sympy2_extended-1.10.2-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting math-verify==0.5.2 (from -r requirements.txt (line 13))\n",
            "  Downloading math_verify-0.5.2-py3-none-any.whl.metadata (347 bytes)\n",
            "Collecting latex2sympy2_extended (from -r requirements.txt (line 12))\n",
            "  Downloading latex2sympy2_extended-1.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.13.2 (from latex2sympy2_extended->-r requirements.txt (line 12))\n",
            "  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from latex2sympy2_extended->-r requirements.txt (line 12)) (1.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirements.txt (line 1)) (2.9.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.6->-r requirements.txt (line 2)) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->-r requirements.txt (line 2)) (2025.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 7)) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.49.0->-r requirements.txt (line 9)) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.49.0->-r requirements.txt (line 9)) (0.22.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->-r requirements.txt (line 2)) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard->-r requirements.txt (line 7)) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.14.6->-r requirements.txt (line 2)) (2025.11.12)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->latex2sympy2_extended->-r requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 7)) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 2)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 2)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.14.6->-r requirements.txt (line 2)) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->-r requirements.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->-r requirements.txt (line 2)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->-r requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->-r requirements.txt (line 2)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->-r requirements.txt (line 2)) (1.22.0)\n",
            "Downloading math_verify-0.5.2-py3-none-any.whl (27 kB)\n",
            "Downloading latex2sympy2_extended-1.0.6-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.26.2-py3-none-any.whl (518 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: antlr4-python3-runtime, loguru, latex2sympy2_extended, math-verify, trl\n",
            "  Attempting uninstall: antlr4-python3-runtime\n",
            "    Found existing installation: antlr4-python3-runtime 4.9.3\n",
            "    Uninstalling antlr4-python3-runtime-4.9.3:\n",
            "      Successfully uninstalled antlr4-python3-runtime-4.9.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "omegaconf 2.3.0 requires antlr4-python3-runtime==4.9.*, but you have antlr4-python3-runtime 4.13.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.13.2 latex2sympy2_extended-1.0.6 loguru-0.7.3 math-verify-0.5.2 trl-0.26.2\n"
          ]
        }
      ],
      "source": [
        "!git clone --depth 1 https://github.com/shibing624/MedicalGPT.git\n",
        "%cd MedicalGPT\n",
        "%ls\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE95bvXdHkWL"
      },
      "source": [
        "## Stage1 咱们开始吧\n",
        "\n",
        "训练步骤如下：\n",
        "\n",
        "1. 确认训练集\n",
        "2. 执行训练脚本\n",
        "\n",
        "训练脚本的执行逻辑如下：\n",
        "1. 导入依赖包\n",
        "2. 设置参数\n",
        "3. 定义各函数并加载训练集\n",
        "4. 加载模型和tokenizer\n",
        "5. 开始训练并评估\n",
        "6. 查看训练结果\n",
        "\n",
        "**以下参数可以根据你的GPU实际情况修改，当前参数是根据Colab的T4单卡GPU（16GB显存）配置的**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YN67uGKTHkWL",
        "outputId": "af6a47e3-92eb-4292-c8ba-c98a6f2e6f5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "en_article_tail500.txt  fever.txt  tianlongbabu.txt\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/pretrain/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aPyRWCMhHkWL",
        "outputId": "2fefdd50-a492-4cfe-9f62-6edace502aa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-23 04:56:35.922352: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766465795.953787    1387 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766465795.963354    1387 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766465795.989721    1387 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766465795.989755    1387 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766465795.989763    1387 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766465795.989769    1387 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-23 04:56:35.996816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[32m2025-12-23 04:56:43.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m364\u001b[0m - \u001b[1mModel args: ModelArguments(model_name_or_path='Qwen/Qwen2.5-0.5B', tokenizer_name_or_path=None, load_in_8bit=False, load_in_4bit=False, cache_dir=None, model_revision='main', hf_hub_token=None, use_fast_tokenizer=False, torch_dtype='bfloat16', device_map='auto', trust_remote_code=True)\u001b[0m\n",
            "\u001b[32m2025-12-23 04:56:43.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m365\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/pretrain', validation_file_dir='./data/pretrain', max_train_samples=20000, max_eval_samples=10, streaming=False, block_size=128, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=1, keep_linebreaks=True)\u001b[0m\n",
            "\u001b[32m2025-12-23 04:56:43.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m366\u001b[0m - \u001b[1mTraining args: Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=30000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=50,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=True,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0002,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-pt-v1/runs/Dec23_04-56-43_7bb3e7c60fab,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs-pt-v1,\n",
            "overwrite_output_dir=True,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=3,\n",
            "per_device_train_batch_size=3,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "use_cpu=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.01,\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-12-23 04:56:43.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m367\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, qlora=False)\u001b[0m\n",
            "\u001b[32m2025-12-23 04:56:43.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m368\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\u001b[0m\n",
            "tokenizer_config.json: 7.23kB [00:00, 36.0MB/s]\n",
            "vocab.json: 2.78MB [00:00, 72.1MB/s]\n",
            "merges.txt: 1.67MB [00:00, 146MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 184MB/s]\n",
            "\u001b[32m2025-12-23 04:56:44.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m476\u001b[0m - \u001b[1mtrain files: ['./data/pretrain/en_article_tail500.txt', './data/pretrain/tianlongbabu.txt', './data/pretrain/fever.txt']\u001b[0m\n",
            "\u001b[32m2025-12-23 04:56:44.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m486\u001b[0m - \u001b[1meval files: ['./data/pretrain/en_article_tail500.txt', './data/pretrain/tianlongbabu.txt', './data/pretrain/fever.txt']\u001b[0m\n",
            "Generating train split: 3876 examples [00:00, 239900.87 examples/s]\n",
            "Generating validation split: 3876 examples [00:00, 420330.49 examples/s]\n",
            "\u001b[32m2025-12-23 04:56:44.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m518\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3876\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3876\n",
            "    })\n",
            "})\u001b[0m\n",
            "Running tokenizer on dataset: 100% 3876/3876 [00:10<00:00, 376.94 examples/s]\n",
            "Running tokenizer on dataset: 100% 3876/3876 [00:10<00:00, 377.69 examples/s]\n",
            "Grouping texts in chunks of 128: 100% 3876/3876 [00:00<00:00, 9016.67 examples/s]\n",
            "Grouping texts in chunks of 128: 100% 3876/3876 [00:00<00:00, 9248.17 examples/s]\n",
            "\u001b[32m2025-12-23 04:57:11.291\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m581\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 2501\u001b[0m\n",
            "\u001b[32m2025-12-23 04:57:11.291\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m582\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
            "\u001b[32m2025-12-23 04:57:11.292\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m583\u001b[0m - \u001b[34m\u001b[1mcontract to work in specified mines and mills. There seemed to be no\n",
            "limit to the factories, forges, refineries, and railways that could be\n",
            "built, to the multitudes that could be employed in conquering a\n",
            "continent. As for the future, that was in the hands of Providence!\n",
            "\n",
            "=Business Theories of Politics.=--As the statesmen of Hamilton's school\n",
            "and the planters of Calhoun's had their theories of government and\n",
            "politics, so the leaders in business enterprise had theirs. It was\n",
            "simple and easily stated. \"It is the duty of the government,\" they\n",
            "ur\u001b[0m\n",
            "\u001b[32m2025-12-23 04:57:11.294\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m595\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2025-12-23 04:57:11.294\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m596\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
            "\u001b[32m2025-12-23 04:57:11.294\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m597\u001b[0m - \u001b[34m\u001b[1mcontract to work in specified mines and mills. There seemed to be no\n",
            "limit to the factories, forges, refineries, and railways that could be\n",
            "built, to the multitudes that could be employed in conquering a\n",
            "continent. As for the future, that was in the hands of Providence!\n",
            "\n",
            "=Business Theories of Politics.=--As the statesmen of Hamilton's school\n",
            "and the planters of Calhoun's had their theories of government and\n",
            "politics, so the leaders in business enterprise had theirs. It was\n",
            "simple and easily stated. \"It is the duty of the government,\" they\n",
            "ur\u001b[0m\n",
            "config.json: 100% 681/681 [00:00<00:00, 7.31MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors: 100% 988M/988M [00:07<00:00, 134MB/s]\n",
            "generation_config.json: 100% 138/138 [00:00<00:00, 1.38MB/s]\n",
            "\u001b[32m2025-12-23 04:57:19.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m656\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2025-12-23 04:57:19.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m661\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
            "\u001b[32m2025-12-23 04:57:19.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m674\u001b[0m - \u001b[1mPeft target_modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[0m\n",
            "\u001b[32m2025-12-23 04:57:19.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m675\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
            "trainable params: 4,399,104 || all params: 498,431,872 || trainable%: 0.8826\n",
            "/content/MedicalGPT/pretraining.py:705: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SavePeftModelTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = SavePeftModelTrainer(\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "\u001b[32m2025-12-23 04:57:20.230\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m720\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "\u001b[32m2025-12-23 04:57:20.840\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m721\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids': tensor([[ 99805,  52801,   3837,  99727, 102461,   3837, 105665,  75882,  39165,\n",
            "          99500,  42411, 109565,  99306,  52801,  81264,  99727, 102461, 105626,\n",
            "          44793,  36987,  37474, 106292, 104139, 115131,   3837,  97639,  35926,\n",
            "          39165, 110121,   3837,  99245,  99500,  16530,  99500,   9370,   3837,\n",
            "          97639,  99190, 112471,   9370, 101453,  81596,  81264,  99727, 104000,\n",
            "          44793,  36987, 103924, 120671,   3837,  56568, 104298, 100457,  99486,\n",
            "          36993, 100219,  52801, 104389,   3837, 100224,  99925, 112730,  36587,\n",
            "         108386,   3837, 108967, 100250,  32945,  37474,  99783, 106052,  36987,\n",
            "         106665,  99295,  16744,   3837, 109739, 117350, 118459,   3837,  77540,\n",
            "          90885, 100141, 102513,   1773,  99727, 102461, 103856, 103856,   3837,\n",
            "          35946, 105189,  49187, 103929,  64272, 111241,  17447, 100080, 101477,\n",
            "           3837,  39973,  98650,  63109, 111520,  99315, 106433,   1773,  99172,\n",
            "         112720,  11622, 100672, 112946,  36407, 110327,  14777, 100036,   3837,\n",
            "         111566, 104501,  89012, 104269,  26288, 109503, 100228, 100215, 100815,\n",
            "         120493,   3837],\n",
            "        [100037,   3837,  99172, 107541,  33447, 103947, 102009,   3837,  77288,\n",
            "          89012, 102987, 104609,  34187,   3837, 107585,  74763, 103036,  16530,\n",
            "          99694,   3837, 110253,  11622, 101270,  32555,  47534,   3837,  31843,\n",
            "          47534, 110253,  99723,  99234,   9370,  99632,  20726,   8997,  99718,\n",
            "          15946, 105501,  91680,  99353,  75061,  99677, 100037,  17447, 116345,\n",
            "         106701,  31843,  47534,   3837, 104578,  99518,  45181,  99283, 100037,\n",
            "          52526,  20221,   3837, 108954,  43288,  30709, 114049,  99261, 100007,\n",
            "          18830, 101073, 103524,  31843,  47534,   3837, 100538, 106097,   3837,\n",
            "          52801,  18493,  99283, 103366,  17447,  31843,  47534,  99632,  20726,\n",
            "           3837, 106911,  99786,  18830, 104361,   3837,  99795, 107585,  99744,\n",
            "         100209,  53222,  99694,  75061,  99677,  99336, 121601,   3837, 106429,\n",
            "          18830,  85336,  42192,  36407,   1773,  75061,  31207, 100956,  49567,\n",
            "          74763,  99639, 106148, 111038,   3837, 104138, 104219, 105187,   3837,\n",
            "         105777,  99786,  99236,  99745,  99236,  99378,   3837, 106682, 111157,\n",
            "          52510, 107691],\n",
            "        [ 75405, 106783,  79766,  44793,  36987,  56568,  99882, 101553, 100469,\n",
            "           3837,  35946,  99364,  16530, 100469,  32945, 107279,  72225, 104853,\n",
            "          27091,  99710,   8997,  37474,  99783, 104639,  99517,  79766,  99686,\n",
            "           9370,  36629,  99225,   3837,  99518,  99639, 104660,   3837, 103961,\n",
            "         101920,   3837, 101317,  15946, 105218, 110963,   8903,   9370, 105748,\n",
            "           3837, 113235,   2073, 103924, 111447,    854, 104494,   3837,  99882,\n",
            "         108158,   1773,  43288,  99854, 105748,  99364,  29524, 104801,  30709,\n",
            "         101953,  18493, 102766, 101317,  15946, 102363, 113698,  27733,   3837,\n",
            "          44063,  42411, 100859,  44729,  14777, 101490, 101490,   9370, 100958,\n",
            "          63789,   1773,  37474,  99783, 105777,  59879,  99296, 105925,   3837,\n",
            "         113201, 100868, 100088,  99364,  29524,  99789,  99955,  99791,  14777,\n",
            "         101425, 101425, 102914,  99898,   8997,  75405, 106783,  79766,  99851,\n",
            "          44793,  36987,  56568,  14053, 109111, 104060,  81264,  37474,  99783,\n",
            "         119332, 108375,  44793,  36987,  43288,  14053,  43288,  63789, 100859,\n",
            "          99632,  14053]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'labels': tensor([[ 99805,  52801,   3837,  99727, 102461,   3837, 105665,  75882,  39165,\n",
            "          99500,  42411, 109565,  99306,  52801,  81264,  99727, 102461, 105626,\n",
            "          44793,  36987,  37474, 106292, 104139, 115131,   3837,  97639,  35926,\n",
            "          39165, 110121,   3837,  99245,  99500,  16530,  99500,   9370,   3837,\n",
            "          97639,  99190, 112471,   9370, 101453,  81596,  81264,  99727, 104000,\n",
            "          44793,  36987, 103924, 120671,   3837,  56568, 104298, 100457,  99486,\n",
            "          36993, 100219,  52801, 104389,   3837, 100224,  99925, 112730,  36587,\n",
            "         108386,   3837, 108967, 100250,  32945,  37474,  99783, 106052,  36987,\n",
            "         106665,  99295,  16744,   3837, 109739, 117350, 118459,   3837,  77540,\n",
            "          90885, 100141, 102513,   1773,  99727, 102461, 103856, 103856,   3837,\n",
            "          35946, 105189,  49187, 103929,  64272, 111241,  17447, 100080, 101477,\n",
            "           3837,  39973,  98650,  63109, 111520,  99315, 106433,   1773,  99172,\n",
            "         112720,  11622, 100672, 112946,  36407, 110327,  14777, 100036,   3837,\n",
            "         111566, 104501,  89012, 104269,  26288, 109503, 100228, 100215, 100815,\n",
            "         120493,   3837],\n",
            "        [100037,   3837,  99172, 107541,  33447, 103947, 102009,   3837,  77288,\n",
            "          89012, 102987, 104609,  34187,   3837, 107585,  74763, 103036,  16530,\n",
            "          99694,   3837, 110253,  11622, 101270,  32555,  47534,   3837,  31843,\n",
            "          47534, 110253,  99723,  99234,   9370,  99632,  20726,   8997,  99718,\n",
            "          15946, 105501,  91680,  99353,  75061,  99677, 100037,  17447, 116345,\n",
            "         106701,  31843,  47534,   3837, 104578,  99518,  45181,  99283, 100037,\n",
            "          52526,  20221,   3837, 108954,  43288,  30709, 114049,  99261, 100007,\n",
            "          18830, 101073, 103524,  31843,  47534,   3837, 100538, 106097,   3837,\n",
            "          52801,  18493,  99283, 103366,  17447,  31843,  47534,  99632,  20726,\n",
            "           3837, 106911,  99786,  18830, 104361,   3837,  99795, 107585,  99744,\n",
            "         100209,  53222,  99694,  75061,  99677,  99336, 121601,   3837, 106429,\n",
            "          18830,  85336,  42192,  36407,   1773,  75061,  31207, 100956,  49567,\n",
            "          74763,  99639, 106148, 111038,   3837, 104138, 104219, 105187,   3837,\n",
            "         105777,  99786,  99236,  99745,  99236,  99378,   3837, 106682, 111157,\n",
            "          52510, 107691],\n",
            "        [ 75405, 106783,  79766,  44793,  36987,  56568,  99882, 101553, 100469,\n",
            "           3837,  35946,  99364,  16530, 100469,  32945, 107279,  72225, 104853,\n",
            "          27091,  99710,   8997,  37474,  99783, 104639,  99517,  79766,  99686,\n",
            "           9370,  36629,  99225,   3837,  99518,  99639, 104660,   3837, 103961,\n",
            "         101920,   3837, 101317,  15946, 105218, 110963,   8903,   9370, 105748,\n",
            "           3837, 113235,   2073, 103924, 111447,    854, 104494,   3837,  99882,\n",
            "         108158,   1773,  43288,  99854, 105748,  99364,  29524, 104801,  30709,\n",
            "         101953,  18493, 102766, 101317,  15946, 102363, 113698,  27733,   3837,\n",
            "          44063,  42411, 100859,  44729,  14777, 101490, 101490,   9370, 100958,\n",
            "          63789,   1773,  37474,  99783, 105777,  59879,  99296, 105925,   3837,\n",
            "         113201, 100868, 100088,  99364,  29524,  99789,  99955,  99791,  14777,\n",
            "         101425, 101425, 102914,  99898,   8997,  75405, 106783,  79766,  99851,\n",
            "          44793,  36987,  56568,  14053, 109111, 104060,  81264,  37474,  99783,\n",
            "         119332, 108375,  44793,  36987,  43288,  14053,  43288,  63789, 100859,\n",
            "          99632,  14053]], device='cuda:0')}\u001b[0m\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "{'loss': 4.3649, 'grad_norm': 2.662637710571289, 'learning_rate': 0.0, 'epoch': 0.0}\n",
            "{'loss': 3.8427, 'grad_norm': 2.7369015216827393, 'learning_rate': 4.2857142857142856e-05, 'epoch': 0.01}\n",
            "{'loss': 3.8684, 'grad_norm': 2.2510342597961426, 'learning_rate': 9.047619047619048e-05, 'epoch': 0.02}\n",
            "{'loss': 3.7237, 'grad_norm': 2.342863082885742, 'learning_rate': 0.0001380952380952381, 'epoch': 0.04}\n",
            "{'loss': 3.7414, 'grad_norm': 2.783025026321411, 'learning_rate': 0.00018571428571428572, 'epoch': 0.05}\n",
            "{'loss': 3.5616, 'grad_norm': 2.780888319015503, 'learning_rate': 0.00019823232323232324, 'epoch': 0.06}\n",
            "  6% 50/834 [00:33<08:49,  1.48it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  9.96it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.89it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 3.469494581222534, 'eval_accuracy': 0.37086614173228344, 'eval_runtime': 0.7669, 'eval_samples_per_second': 13.039, 'eval_steps_per_second': 5.216, 'epoch': 0.06}\n",
            "  6% 50/834 [00:34<08:49,  1.48it/s]\n",
            "100% 4/4 [00:00<00:00,  7.46it/s]\u001b[A\n",
            "{'loss': 3.6554, 'grad_norm': 2.615678310394287, 'learning_rate': 0.0001957070707070707, 'epoch': 0.07}\n",
            "{'loss': 3.5565, 'grad_norm': 2.670957326889038, 'learning_rate': 0.0001931818181818182, 'epoch': 0.08}\n",
            "{'loss': 3.7362, 'grad_norm': 2.5416817665100098, 'learning_rate': 0.00019065656565656565, 'epoch': 0.1}\n",
            "{'loss': 3.6488, 'grad_norm': 3.268122434616089, 'learning_rate': 0.00018813131313131313, 'epoch': 0.11}\n",
            "{'loss': 3.7145, 'grad_norm': 2.5344998836517334, 'learning_rate': 0.00018560606060606061, 'epoch': 0.12}\n",
            " 12% 100/834 [01:06<08:00,  1.53it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  9.34it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.58it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.3957297801971436, 'eval_accuracy': 0.3700787401574803, 'eval_runtime': 0.7651, 'eval_samples_per_second': 13.07, 'eval_steps_per_second': 5.228, 'epoch': 0.12}\n",
            " 12% 100/834 [01:07<08:00,  1.53it/s]\n",
            "100% 4/4 [00:00<00:00,  7.14it/s]\u001b[A\n",
            "{'loss': 3.5888, 'grad_norm': 2.5746119022369385, 'learning_rate': 0.0001830808080808081, 'epoch': 0.13}\n",
            "{'loss': 3.5134, 'grad_norm': 2.7358458042144775, 'learning_rate': 0.00018055555555555557, 'epoch': 0.14}\n",
            "{'loss': 3.4924, 'grad_norm': 2.326528310775757, 'learning_rate': 0.00017803030303030303, 'epoch': 0.16}\n",
            "{'loss': 3.5109, 'grad_norm': 2.4921517372131348, 'learning_rate': 0.0001755050505050505, 'epoch': 0.17}\n",
            "{'loss': 3.4465, 'grad_norm': 2.4825711250305176, 'learning_rate': 0.000172979797979798, 'epoch': 0.18}\n",
            " 18% 150/834 [01:41<07:45,  1.47it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  8.84it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.33it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.384777784347534, 'eval_accuracy': 0.38188976377952755, 'eval_runtime': 0.7795, 'eval_samples_per_second': 12.828, 'eval_steps_per_second': 5.131, 'epoch': 0.18}\n",
            " 18% 150/834 [01:41<07:45,  1.47it/s]\n",
            "100% 4/4 [00:00<00:00,  6.95it/s]\u001b[A\n",
            "{'loss': 3.574, 'grad_norm': 2.8006069660186768, 'learning_rate': 0.00017045454545454547, 'epoch': 0.19}\n",
            "{'loss': 3.3414, 'grad_norm': 2.3214573860168457, 'learning_rate': 0.00016792929292929295, 'epoch': 0.2}\n",
            "{'loss': 3.6418, 'grad_norm': 2.7570717334747314, 'learning_rate': 0.0001654040404040404, 'epoch': 0.22}\n",
            "{'loss': 3.4888, 'grad_norm': 2.4599506855010986, 'learning_rate': 0.0001628787878787879, 'epoch': 0.23}\n",
            "{'loss': 3.4044, 'grad_norm': 2.375251054763794, 'learning_rate': 0.00016035353535353536, 'epoch': 0.24}\n",
            " 24% 200/834 [02:15<06:58,  1.51it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  9.00it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.43it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.3135266304016113, 'eval_accuracy': 0.38818897637795274, 'eval_runtime': 0.7716, 'eval_samples_per_second': 12.961, 'eval_steps_per_second': 5.184, 'epoch': 0.24}\n",
            " 24% 200/834 [02:16<06:58,  1.51it/s]\n",
            "100% 4/4 [00:00<00:00,  7.01it/s]\u001b[A\n",
            "{'loss': 3.5141, 'grad_norm': 2.61372709274292, 'learning_rate': 0.00015782828282828284, 'epoch': 0.25}\n",
            "{'loss': 3.451, 'grad_norm': 3.038224458694458, 'learning_rate': 0.0001553030303030303, 'epoch': 0.26}\n",
            "{'loss': 3.4418, 'grad_norm': 2.2720625400543213, 'learning_rate': 0.00015277777777777777, 'epoch': 0.28}\n",
            "{'loss': 3.5558, 'grad_norm': 2.536780595779419, 'learning_rate': 0.00015025252525252526, 'epoch': 0.29}\n",
            "{'loss': 3.4541, 'grad_norm': 2.3049979209899902, 'learning_rate': 0.00014772727272727274, 'epoch': 0.3}\n",
            " 30% 250/834 [02:49<06:30,  1.50it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  9.04it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.42it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.25339937210083, 'eval_accuracy': 0.3952755905511811, 'eval_runtime': 0.7734, 'eval_samples_per_second': 12.93, 'eval_steps_per_second': 5.172, 'epoch': 0.3}\n",
            " 30% 250/834 [02:50<06:30,  1.50it/s]\n",
            "100% 4/4 [00:00<00:00,  7.03it/s]\u001b[A\n",
            "{'loss': 3.5747, 'grad_norm': 2.590599536895752, 'learning_rate': 0.00014520202020202022, 'epoch': 0.31}\n",
            "{'loss': 3.5652, 'grad_norm': 2.6194186210632324, 'learning_rate': 0.00014267676767676767, 'epoch': 0.32}\n",
            "{'loss': 3.3796, 'grad_norm': 2.60723876953125, 'learning_rate': 0.00014015151515151518, 'epoch': 0.34}\n",
            "{'loss': 3.5683, 'grad_norm': 1.9630181789398193, 'learning_rate': 0.00013762626262626263, 'epoch': 0.35}\n",
            "{'loss': 3.5825, 'grad_norm': 2.476257801055908, 'learning_rate': 0.0001351010101010101, 'epoch': 0.36}\n",
            " 36% 300/834 [03:23<05:55,  1.50it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  9.22it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.42it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.2452151775360107, 'eval_accuracy': 0.3984251968503937, 'eval_runtime': 0.7735, 'eval_samples_per_second': 12.929, 'eval_steps_per_second': 5.172, 'epoch': 0.36}\n",
            " 36% 300/834 [03:24<05:55,  1.50it/s]\n",
            "100% 4/4 [00:00<00:00,  6.99it/s]\u001b[A\n",
            "{'loss': 3.298, 'grad_norm': 2.1655807495117188, 'learning_rate': 0.00013257575757575756, 'epoch': 0.37}\n",
            "{'loss': 3.476, 'grad_norm': 2.282831907272339, 'learning_rate': 0.00013005050505050507, 'epoch': 0.38}\n",
            "{'loss': 3.4654, 'grad_norm': 2.462603807449341, 'learning_rate': 0.00012752525252525255, 'epoch': 0.4}\n",
            "{'loss': 3.7164, 'grad_norm': 2.8174808025360107, 'learning_rate': 0.000125, 'epoch': 0.41}\n",
            "{'loss': 3.6148, 'grad_norm': 2.4084041118621826, 'learning_rate': 0.00012247474747474748, 'epoch': 0.42}\n",
            " 42% 350/834 [03:57<05:21,  1.50it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  9.00it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.34it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.2184596061706543, 'eval_accuracy': 0.40078740157480314, 'eval_runtime': 0.7795, 'eval_samples_per_second': 12.829, 'eval_steps_per_second': 5.132, 'epoch': 0.42}\n",
            " 42% 350/834 [03:58<05:21,  1.50it/s]\n",
            "100% 4/4 [00:00<00:00,  6.93it/s]\u001b[A\n",
            "{'loss': 3.3923, 'grad_norm': 2.6720566749572754, 'learning_rate': 0.00011994949494949495, 'epoch': 0.43}\n",
            "{'loss': 3.5187, 'grad_norm': 2.7918663024902344, 'learning_rate': 0.00011742424242424244, 'epoch': 0.44}\n",
            "{'loss': 3.4307, 'grad_norm': 2.476665735244751, 'learning_rate': 0.00011489898989898991, 'epoch': 0.46}\n",
            "{'loss': 3.3192, 'grad_norm': 3.2224559783935547, 'learning_rate': 0.00011237373737373738, 'epoch': 0.47}\n",
            "{'loss': 3.3593, 'grad_norm': 2.5837185382843018, 'learning_rate': 0.00010984848484848484, 'epoch': 0.48}\n",
            " 48% 400/834 [04:31<04:50,  1.49it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  9.23it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.42it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.21697998046875, 'eval_accuracy': 0.39448818897637794, 'eval_runtime': 0.7717, 'eval_samples_per_second': 12.958, 'eval_steps_per_second': 5.183, 'epoch': 0.48}\n",
            " 48% 400/834 [04:32<04:50,  1.49it/s]\n",
            "100% 4/4 [00:00<00:00,  7.03it/s]\u001b[A\n",
            "{'loss': 3.4564, 'grad_norm': 2.187380075454712, 'learning_rate': 0.00010732323232323234, 'epoch': 0.49}\n",
            "{'loss': 3.5155, 'grad_norm': 2.611198902130127, 'learning_rate': 0.0001047979797979798, 'epoch': 0.5}\n",
            "{'loss': 3.4299, 'grad_norm': 2.4081382751464844, 'learning_rate': 0.00010227272727272727, 'epoch': 0.52}\n",
            "{'loss': 3.3984, 'grad_norm': 2.613616943359375, 'learning_rate': 9.974747474747475e-05, 'epoch': 0.53}\n",
            "{'loss': 3.5044, 'grad_norm': 2.788773775100708, 'learning_rate': 9.722222222222223e-05, 'epoch': 0.54}\n",
            " 54% 450/834 [05:06<04:17,  1.49it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  8.91it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.41it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.1700220108032227, 'eval_accuracy': 0.4086614173228346, 'eval_runtime': 0.7821, 'eval_samples_per_second': 12.786, 'eval_steps_per_second': 5.115, 'epoch': 0.54}\n",
            " 54% 450/834 [05:06<04:17,  1.49it/s]\n",
            "100% 4/4 [00:00<00:00,  7.00it/s]\u001b[A\n",
            "{'loss': 3.4777, 'grad_norm': 2.640551805496216, 'learning_rate': 9.469696969696971e-05, 'epoch': 0.55}\n",
            "{'loss': 3.171, 'grad_norm': 2.7017667293548584, 'learning_rate': 9.217171717171718e-05, 'epoch': 0.56}\n",
            "{'loss': 3.5754, 'grad_norm': 2.4231462478637695, 'learning_rate': 8.964646464646466e-05, 'epoch': 0.58}\n",
            "{'loss': 3.364, 'grad_norm': 2.9380478858947754, 'learning_rate': 8.712121212121212e-05, 'epoch': 0.59}\n",
            "{'loss': 3.4838, 'grad_norm': 2.9490060806274414, 'learning_rate': 8.459595959595959e-05, 'epoch': 0.6}\n",
            " 60% 500/834 [05:40<03:41,  1.51it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  9.00it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.36it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.1483092308044434, 'eval_accuracy': 0.4086614173228346, 'eval_runtime': 0.7781, 'eval_samples_per_second': 12.852, 'eval_steps_per_second': 5.141, 'epoch': 0.6}\n",
            " 60% 500/834 [05:41<03:41,  1.51it/s]\n",
            "100% 4/4 [00:00<00:00,  6.93it/s]\u001b[A\n",
            "{'loss': 3.4511, 'grad_norm': 2.3723232746124268, 'learning_rate': 8.207070707070707e-05, 'epoch': 0.61}\n",
            "{'loss': 3.3253, 'grad_norm': 2.6612112522125244, 'learning_rate': 7.954545454545455e-05, 'epoch': 0.62}\n",
            "{'loss': 3.4636, 'grad_norm': 2.629765033721924, 'learning_rate': 7.702020202020203e-05, 'epoch': 0.64}\n",
            "{'loss': 3.4424, 'grad_norm': 2.556492805480957, 'learning_rate': 7.44949494949495e-05, 'epoch': 0.65}\n",
            "{'loss': 3.3787, 'grad_norm': 2.6288695335388184, 'learning_rate': 7.196969696969698e-05, 'epoch': 0.66}\n",
            " 66% 550/834 [06:15<03:09,  1.50it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  9.21it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.37it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.1326255798339844, 'eval_accuracy': 0.41338582677165353, 'eval_runtime': 0.7726, 'eval_samples_per_second': 12.943, 'eval_steps_per_second': 5.177, 'epoch': 0.66}\n",
            " 66% 550/834 [06:15<03:09,  1.50it/s]\n",
            "100% 4/4 [00:00<00:00,  6.96it/s]\u001b[A\n",
            "{'loss': 3.3266, 'grad_norm': 2.4826407432556152, 'learning_rate': 6.944444444444444e-05, 'epoch': 0.67}\n",
            "{'loss': 3.4087, 'grad_norm': 2.5332326889038086, 'learning_rate': 6.691919191919192e-05, 'epoch': 0.68}\n",
            "{'loss': 3.3455, 'grad_norm': 2.576907157897949, 'learning_rate': 6.439393939393939e-05, 'epoch': 0.7}\n",
            "{'loss': 3.374, 'grad_norm': 2.6851816177368164, 'learning_rate': 6.186868686868687e-05, 'epoch': 0.71}\n",
            "{'loss': 3.3815, 'grad_norm': 2.459540367126465, 'learning_rate': 5.9343434343434345e-05, 'epoch': 0.72}\n",
            " 72% 600/834 [06:49<02:35,  1.50it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  8.96it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.38it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.102337598800659, 'eval_accuracy': 0.41338582677165353, 'eval_runtime': 0.7765, 'eval_samples_per_second': 12.878, 'eval_steps_per_second': 5.151, 'epoch': 0.72}\n",
            " 72% 600/834 [06:50<02:35,  1.50it/s]\n",
            "100% 4/4 [00:00<00:00,  6.99it/s]\u001b[A\n",
            "{'loss': 3.249, 'grad_norm': 2.5419325828552246, 'learning_rate': 5.6818181818181825e-05, 'epoch': 0.73}\n",
            "{'loss': 3.4794, 'grad_norm': 2.7224905490875244, 'learning_rate': 5.42929292929293e-05, 'epoch': 0.74}\n",
            "{'loss': 3.3907, 'grad_norm': 2.5372188091278076, 'learning_rate': 5.1767676767676765e-05, 'epoch': 0.76}\n",
            "{'loss': 3.1198, 'grad_norm': 2.7062246799468994, 'learning_rate': 4.9242424242424245e-05, 'epoch': 0.77}\n",
            "{'loss': 3.3557, 'grad_norm': 2.884944438934326, 'learning_rate': 4.671717171717172e-05, 'epoch': 0.78}\n",
            " 78% 650/834 [07:23<02:02,  1.50it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  9.22it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.40it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.099238872528076, 'eval_accuracy': 0.4094488188976378, 'eval_runtime': 0.7766, 'eval_samples_per_second': 12.877, 'eval_steps_per_second': 5.151, 'epoch': 0.78}\n",
            " 78% 650/834 [07:24<02:02,  1.50it/s]\n",
            "100% 4/4 [00:00<00:00,  6.94it/s]\u001b[A\n",
            "{'loss': 3.3082, 'grad_norm': 2.7234199047088623, 'learning_rate': 4.41919191919192e-05, 'epoch': 0.79}\n",
            "{'loss': 3.3178, 'grad_norm': 2.6960668563842773, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.8}\n",
            "{'loss': 3.2785, 'grad_norm': 2.408557653427124, 'learning_rate': 3.9141414141414145e-05, 'epoch': 0.82}\n",
            "{'loss': 3.2969, 'grad_norm': 2.718080520629883, 'learning_rate': 3.661616161616162e-05, 'epoch': 0.83}\n",
            "{'loss': 3.3398, 'grad_norm': 2.1534392833709717, 'learning_rate': 3.409090909090909e-05, 'epoch': 0.84}\n",
            " 84% 700/834 [07:57<01:29,  1.50it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  9.21it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.42it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.1019835472106934, 'eval_accuracy': 0.4094488188976378, 'eval_runtime': 0.7668, 'eval_samples_per_second': 13.041, 'eval_steps_per_second': 5.216, 'epoch': 0.84}\n",
            " 84% 700/834 [07:58<01:29,  1.50it/s]\n",
            "100% 4/4 [00:00<00:00,  7.01it/s]\u001b[A\n",
            "{'loss': 3.4757, 'grad_norm': 2.4204766750335693, 'learning_rate': 3.1565656565656566e-05, 'epoch': 0.85}\n",
            "{'loss': 3.5089, 'grad_norm': 2.6267647743225098, 'learning_rate': 2.904040404040404e-05, 'epoch': 0.86}\n",
            "{'loss': 3.4507, 'grad_norm': 3.0365986824035645, 'learning_rate': 2.6515151515151516e-05, 'epoch': 0.88}\n",
            "{'loss': 3.2887, 'grad_norm': 2.452011823654175, 'learning_rate': 2.398989898989899e-05, 'epoch': 0.89}\n",
            "{'loss': 3.3481, 'grad_norm': 2.5190155506134033, 'learning_rate': 2.1464646464646466e-05, 'epoch': 0.9}\n",
            " 90% 750/834 [08:31<00:55,  1.50it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  9.06it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.43it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.101022243499756, 'eval_accuracy': 0.4078740157480315, 'eval_runtime': 0.767, 'eval_samples_per_second': 13.037, 'eval_steps_per_second': 5.215, 'epoch': 0.9}\n",
            " 90% 750/834 [08:32<00:55,  1.50it/s]\n",
            "100% 4/4 [00:00<00:00,  7.06it/s]\u001b[A\n",
            "{'loss': 3.3091, 'grad_norm': 3.0233945846557617, 'learning_rate': 1.893939393939394e-05, 'epoch': 0.91}\n",
            "{'loss': 3.3472, 'grad_norm': 2.384373903274536, 'learning_rate': 1.6414141414141416e-05, 'epoch': 0.92}\n",
            "{'loss': 3.2723, 'grad_norm': 2.4281115531921387, 'learning_rate': 1.388888888888889e-05, 'epoch': 0.94}\n",
            "{'loss': 3.1899, 'grad_norm': 2.2629575729370117, 'learning_rate': 1.1363636363636365e-05, 'epoch': 0.95}\n",
            "{'loss': 3.3843, 'grad_norm': 2.8946597576141357, 'learning_rate': 8.838383838383838e-06, 'epoch': 0.96}\n",
            " 96% 800/834 [09:06<00:22,  1.49it/s]\n",
            "  0% 0/4 [00:00<?, ?it/s]\u001b[A\n",
            " 50% 2/4 [00:00<00:00,  8.90it/s]\u001b[A\n",
            " 75% 3/4 [00:00<00:00,  6.35it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.091337203979492, 'eval_accuracy': 0.4086614173228346, 'eval_runtime': 0.7798, 'eval_samples_per_second': 12.824, 'eval_steps_per_second': 5.13, 'epoch': 0.96}\n",
            " 96% 800/834 [09:06<00:22,  1.49it/s]\n",
            "100% 4/4 [00:00<00:00,  6.95it/s]\u001b[A\n",
            "{'loss': 3.2339, 'grad_norm': 2.785813331604004, 'learning_rate': 6.313131313131314e-06, 'epoch': 0.97}\n",
            "{'loss': 3.3134, 'grad_norm': 2.8589587211608887, 'learning_rate': 3.7878787878787882e-06, 'epoch': 0.98}\n",
            "{'loss': 3.4174, 'grad_norm': 2.641127347946167, 'learning_rate': 1.2626262626262627e-06, 'epoch': 1.0}\n",
            "{'train_runtime': 570.0334, 'train_samples_per_second': 4.387, 'train_steps_per_second': 1.463, 'train_loss': 3.4547316993740824, 'epoch': 1.0}\n",
            "100% 834/834 [09:30<00:00,  1.46it/s]\n",
            "***** train metrics *****\n",
            "  epoch                    =        1.0\n",
            "  total_flos               =   648097GF\n",
            "  train_loss               =     3.4547\n",
            "  train_runtime            = 0:09:30.03\n",
            "  train_samples            =       2501\n",
            "  train_samples_per_second =      4.387\n",
            "  train_steps_per_second   =      1.463\n",
            "\u001b[32m2025-12-23 05:06:51.776\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m738\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 570.0334, 'train_samples_per_second': 4.387, 'train_steps_per_second': 1.463, 'total_flos': 695888898981888.0, 'train_loss': 3.4547316993740824, 'epoch': 1.0, 'train_samples': 2501}\u001b[0m\n",
            "\u001b[32m2025-12-23 05:06:51.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m739\u001b[0m - \u001b[1mSaving model checkpoint to outputs-pt-v1\u001b[0m\n",
            "\u001b[32m2025-12-23 05:06:52.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m747\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
            "100% 4/4 [00:00<00:00,  7.15it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        1.0\n",
            "  eval_accuracy           =     0.4094\n",
            "  eval_loss               =     3.0909\n",
            "  eval_runtime            = 0:00:00.76\n",
            "  eval_samples            =         10\n",
            "  eval_samples_per_second =     13.009\n",
            "  eval_steps_per_second   =      5.204\n",
            "  perplexity              =    21.9977\n",
            "\u001b[32m2025-12-23 05:06:53.234\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m760\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 3.0909368991851807, 'eval_accuracy': 0.4094488188976378, 'eval_runtime': 0.7687, 'eval_samples_per_second': 13.009, 'eval_steps_per_second': 5.204, 'epoch': 1.0, 'eval_samples': 10, 'perplexity': 21.997677930745233}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python pretraining.py \\\n",
        "    --model_name_or_path Qwen/Qwen2.5-0.5B \\\n",
        "    --train_file_dir ./data/pretrain \\\n",
        "    --validation_file_dir ./data/pretrain \\\n",
        "    --per_device_train_batch_size 3 \\\n",
        "    --per_device_eval_batch_size 3 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --use_peft True \\\n",
        "    --seed 42 \\\n",
        "    --bf16 \\\n",
        "    --max_train_samples 20000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --eval_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --preprocessing_num_workers 1 \\\n",
        "    --block_size 128 \\\n",
        "    --group_by_length True \\\n",
        "    --output_dir outputs-pt-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype bfloat16 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --gradient_checkpointing True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BwvxLqIjHkWM",
        "outputId": "a692a2d3-851d-4a8e-b816-898737f4eb25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 22M\n",
            "-rw-r--r-- 1 root root 1.1K Dec 23 05:06 adapter_config.json\n",
            "-rw-r--r-- 1 root root  17M Dec 23 05:06 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root  605 Dec 23 05:06 added_tokens.json\n",
            "-rw-r--r-- 1 root root  472 Dec 23 05:06 all_results.json\n",
            "-rw-r--r-- 1 root root 2.4K Dec 23 05:06 chat_template.jinja\n",
            "drwxr-xr-x 2 root root 4.0K Dec 23 05:03 \u001b[0m\u001b[01;34mcheckpoint-500\u001b[0m/\n",
            "drwxr-xr-x 2 root root 4.0K Dec 23 05:06 \u001b[01;34mcheckpoint-834\u001b[0m/\n",
            "-rw-r--r-- 1 root root  263 Dec 23 05:06 eval_results.json\n",
            "-rw-r--r-- 1 root root 1.6M Dec 23 05:06 merges.txt\n",
            "-rw-r--r-- 1 root root 5.1K Dec 23 05:06 README.md\n",
            "drwxr-xr-x 3 root root 4.0K Dec 23 04:57 \u001b[01;34mruns\u001b[0m/\n",
            "-rw-r--r-- 1 root root  616 Dec 23 05:06 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 4.7K Dec 23 05:06 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  20K Dec 23 05:06 trainer_state.json\n",
            "-rw-r--r-- 1 root root  229 Dec 23 05:06 train_results.json\n",
            "-rw-r--r-- 1 root root 3.3M Dec 23 05:06 vocab.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-pt-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmeajUFNHkWM"
      },
      "source": [
        "模型训练结果：\n",
        "- 使用lora训练模型，则保存的lora权重是`adapter_model.safetensors`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
        "- 日志保存在`output_dir/runs`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Xi1s74F2HkWM"
      },
      "source": [
        "lora模型权重合并到base model，合并后的模型保存在`--output_dir`目录下，合并方法如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "igvNbJQIHkWM",
        "outputId": "387b65b9-f56b-4f71-e592-5abd8e4d563b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-23 05:18:58.167603: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766467138.188154    7181 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766467138.194388    7181 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766467138.210785    7181 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766467138.210820    7181 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766467138.210826    7181 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766467138.210829    7181 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-23 05:18:58.215565: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(base_model='Qwen/Qwen2.5-0.5B', tokenizer_path=None, lora_model='outputs-pt-v1', resize_emb=False, output_dir='merged-pt/', hf_hub_model_id='', hf_hub_token=None)\n",
            "Base model: Qwen/Qwen2.5-0.5B\n",
            "LoRA model: outputs-pt-v1\n",
            "Loading LoRA for causal language model\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Merging with merge_and_unload...\n",
            "Saving to Hugging Face format...\n",
            "Done! model saved to merged-pt/\n"
          ]
        }
      ],
      "source": [
        "!python merge_peft_adapter.py \\\n",
        "    --base_model Qwen/Qwen2.5-0.5B --lora_model outputs-pt-v1 --output_dir merged-pt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Fit1cbeqHkWM",
        "outputId": "3c856099-1996-47b6-ae0e-f9711e7e9e14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 958M\n",
            "-rw-r--r-- 1 root root  605 Dec 23 05:19 added_tokens.json\n",
            "-rw-r--r-- 1 root root 2.4K Dec 23 05:19 chat_template.jinja\n",
            "-rw-r--r-- 1 root root 1.3K Dec 23 05:19 config.json\n",
            "-rw-r--r-- 1 root root  117 Dec 23 05:19 generation_config.json\n",
            "-rw-r--r-- 1 root root 1.6M Dec 23 05:19 merges.txt\n",
            "-rw-r--r-- 1 root root 943M Dec 23 05:19 model.safetensors\n",
            "-rw-r--r-- 1 root root  616 Dec 23 05:19 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 4.6K Dec 23 05:19 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  11M Dec 23 05:19 tokenizer.json\n",
            "-rw-r--r-- 1 root root 2.7M Dec 23 05:19 vocab.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh merged-pt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dCHm5qi0HkWM",
        "outputId": "38670edc-2b29-4654-9876-9edc7f6cee41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151643,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 896,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4864,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 24,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 14,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_mrope\": false,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%cat merged-pt/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf91jrp6HkWM"
      },
      "source": [
        "Stage1 增量预训练完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T13:56:17.081153Z",
          "start_time": "2023-06-15T13:56:17.032821Z"
        },
        "id": "mdb0J6lRHkWM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "UVWVXYaRHkWM"
      },
      "source": [
        "# Stage 2: Supervised FineTuning\n",
        "\n",
        "第二阶段：SFT(Supervised Fine-tuning)有监督微调，构造指令微调数据集，在预训练模型基础上做指令精调，以对齐指令意图，并注入领域知识\n",
        "\n",
        "| Stage 2: Supervised Fine-tuning | [supervised_finetuning.py](https://github.com/shibing624/MedicalGPT/blob/main/supervised_finetuning.py) | [run_sft.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_sft.sh)  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "iPtTvllMHkWM"
      },
      "source": [
        "#### 说明：\n",
        "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
        "\n",
        "1. 生成模型：使用的是Qwen/Qwen2.5-0.5B 或者 Stage1得到的预训练模型\n",
        "2. 数据集：SFT阶段使用的是使用的是Belle的1千条抽样数据，位于`data/finetune`文件夹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nPI3MLgfHkWM"
      },
      "source": [
        "## Stage2 咱们开始吧\n",
        "\n",
        "训练步骤如下：\n",
        "\n",
        "1. 确认训练集\n",
        "2. 执行训练脚本\n",
        "\n",
        "训练脚本的执行逻辑如下：\n",
        "1. 导入依赖包\n",
        "2. 设置参数\n",
        "3. 定义各函数并加载训练集\n",
        "4. 加载模型和tokenizer\n",
        "5. 开始训练并评估\n",
        "6. 查看训练结果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T13:58:38.966506Z",
          "start_time": "2023-06-15T13:58:38.778132Z"
        },
        "id": "EUVZ2TebHkWM",
        "outputId": "86358130-6934-4a5d-e7ae-2e930799caf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "medical_sft_1K_format.jsonl        sharegpt_zh_1K_format.jsonl\n",
            "numina_cot_sharegpt_data_1k.jsonl\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/finetune"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) 备份原来的（含 id 的）文件\n",
        "!mv ./data/finetune/numina_cot_sharegpt_data_1k.jsonl ./data/finetune/numina_cot_sharegpt_data_1k.jsonl.bak\n",
        "\n",
        "# 2) 用 strict 版本替换成脚本会读到的文件名\n",
        "!cp ./data/finetune/numina_cot_sharegpt_data_1k.strict.jsonl ./data/finetune/numina_cot_sharegpt_data_1k.jsonl\n",
        "\n",
        "# 3) 自检：确认现在目录里已经是“替换后的”\n",
        "!ls -lh ./data/finetune/numina_cot_sharegpt_data_1k.jsonl*"
      ],
      "metadata": {
        "id": "eMdKhDixMRz-",
        "outputId": "ce2ce4fe-96e9-4e88-8cdb-535b2e39dfb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat './data/finetune/numina_cot_sharegpt_data_1k.strict.jsonl': No such file or directory\n",
            "-rw-r--r-- 1 root root 1.6M Dec 23 04:54 ./data/finetune/numina_cot_sharegpt_data_1k.jsonl.bak\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DnODCDouHkWM",
        "outputId": "6fcff337-f1a7-4e4c-98dc-f80831e2115b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-23 05:20:36.576044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766467236.597086    7623 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766467236.603382    7623 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766467236.618836    7623 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766467236.618866    7623 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766467236.618870    7623 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766467236.618873    7623 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-23 05:20:36.623472: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[32m2025-12-23 05:20:43.095\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m192\u001b[0m - \u001b[33m\u001b[1mYou may set max_train_samples = -1 to run all samples in production.\u001b[0m\n",
            "\u001b[32m2025-12-23 05:20:43.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m346\u001b[0m - \u001b[1mModel args: ModelArguments(model_name_or_path='merged-pt', load_in_8bit=False, load_in_4bit=False, tokenizer_name_or_path=None, cache_dir=None, model_revision='main', hf_hub_token=None, use_fast_tokenizer=False, torch_dtype='bfloat16', device_map='auto', trust_remote_code=True, rope_scaling=None, flash_attn=False, shift_attn=False, neft_alpha=0)\u001b[0m\n",
            "\u001b[32m2025-12-23 05:20:43.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m347\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/finetune', validation_file_dir='./data/finetune', max_train_samples=1000, max_eval_samples=10, ignore_pad_token_for_loss=True, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=1)\u001b[0m\n",
            "\u001b[32m2025-12-23 05:20:43.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m348\u001b[0m - \u001b[1mTraining args: Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=30000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=50,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-sft-v1/runs/Dec23_05-20-43_7bb3e7c60fab,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs-sft-v1,\n",
            "overwrite_output_dir=True,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "use_cpu=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.05,\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-12-23 05:20:43.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m349\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, train_on_inputs=False, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, qlora=False, model_max_length=512, template_name='vicuna')\u001b[0m\n",
            "\u001b[32m2025-12-23 05:20:43.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\u001b[0m\n",
            "\u001b[32m2025-12-23 05:20:43.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m376\u001b[0m - \u001b[1mAdd bos_token: <|endoftext|>, bos_token_id: 151643\u001b[0m\n",
            "\u001b[32m2025-12-23 05:20:43.499\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m383\u001b[0m - \u001b[34m\u001b[1mTokenizer: Qwen2Tokenizer(name_or_path='merged-pt', vocab_size=151643, model_max_length=131072, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "}\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-12-23 05:20:43.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m411\u001b[0m - \u001b[1mtrain files: ['./data/finetune/medical_sft_1K_format.jsonl', './data/finetune/sharegpt_zh_1K_format.jsonl']\u001b[0m\n",
            "\u001b[32m2025-12-23 05:20:43.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m416\u001b[0m - \u001b[1meval files: ['./data/finetune/medical_sft_1K_format.jsonl', './data/finetune/sharegpt_zh_1K_format.jsonl']\u001b[0m\n",
            "Generating train split: 2000 examples [00:00, 59656.99 examples/s]\n",
            "Generating validation split: 2000 examples [00:00, 77621.27 examples/s]\n",
            "\u001b[32m2025-12-23 05:20:43.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m432\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['conversations'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['conversations'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\u001b[0m\n",
            "\u001b[32m2025-12-23 05:20:43.822\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m534\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'conversations': [{'from': 'human', 'value': '做广告者。'}, {'from': 'gpt', 'value': '当然。作为广告客户，我如何帮助您？您广告活动的目标是什么？您的目标受众是什么？请提供更多信息，以便我能够为您提供更有针对性的支持。'}, {'from': 'human', 'value': '请为我找到FOMO的替代概念，以便我将其用作广告。\\n例如，我为某个受众利用FOMO来创造类似“我能排除某人吗？”或“我能变得有阶级意识吗？”等概念。\\n您需要为我找到FOMO的其他替代概念，这将对我创建广告内容很有帮助。'}, {'from': 'gpt', 'value': '以下是一些你可以用于广告活动的替代概念：\\n1. 紧迫性：在优惠活动周围创造一种紧迫感，让人们感到必须立刻行动，以免错失机会。\\n2. 独家性：让人们感到他们正在购买独特的东西，而这些东西不是每个人都可以得到的。\\n3. 稀缺性：在促销活动周围创造一种稀缺感，让人们感到可用的产品数量有限。\\n4. 新鲜感：强调产品或服务是新的和创新的，以及如何为人们的生活带来积极变化。\\n5. 独特好处：突出产品或服务的独特好处，以及如何解决你目标受众的特定问题。\\n这些只是一些你可以用于广告活动的替代概念的例子。重要的是你要了解你目标受众并能够创建一个与他们共鸣的信息。'}, {'from': 'human', 'value': 'Benissimo，列出其他10个概念。'}, {'from': 'gpt', 'value': '以下是另外10个可供广告活动使用的替代概念：\\n1. 便利性：突出产品或服务可以使人们的生活更简单、更方便。\\n2. 质量：强调产品或服务的质量，并说明它如何与竞争对手相比有所区别。\\n3. 流行度：让购买者感受到他们正在购买受欢迎的物品，有很多其他人已经选择了这个产品。\\n4. 节约：强调产品或服务可以帮助节省金钱或时间。\\n5. 个性化：强调产品或服务可以根据人们的具体需求进行个性化定制。\\n6. 满意保证：强调您的满意保证政策，并说明这可以给购买者带来安心，如果不满意可以退货。\\n7. 支持：强调您在销售前后提供的支持。\\n8. 透明度：强调您的透明度，在报价方面让人们感觉他们确切知道自己正在购买什么。\\n9. 趋势：突显产品或服务与当前趋势保持一致，并说明它如何成为人们生活中的时尚附加品。\\n10. 价值：强调产品或服务的价值，证明购买者可以花费相应的价格获得很多物品。\\n这些都是另外10个替代概念，可供广告活动使用。希望这些可以为你提供新的灵感，让你更好地创建下一个广告内容。'}]}\u001b[0m\n",
            "Running tokenizer on dataset: 100% 1000/1000 [00:13<00:00, 71.68 examples/s]\n",
            "Filter: 100% 998/998 [00:00<00:00, 2698.13 examples/s]\n",
            "\u001b[32m2025-12-23 05:21:00.923\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m551\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 998\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:00.923\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m552\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:00.924\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m553\u001b[0m - \u001b[34m\u001b[1mDecode input_ids[0]:\n",
            "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: 做广告者。 ASSISTANT:当然。作为广告客户，我如何帮助您？您广告活动的目标是什么？您的目标受众是什么？请提供更多信息，以便我能够为您提供更有针对性的支持。<|endoftext|></s>USER: 请为我找到FOMO的替代概念，以便我将其用作广告。\n",
            "例如，我为某个受众利用FOMO来创造类似“我能排除某人吗？”或“我能变得有阶级意识吗？”等概念。\n",
            "您需要为我找到FOMO的其他替代概念，这将对我创建广告内容很有帮助。 ASSISTANT:以下是一些你可以用于广告活动的替代概念：\n",
            "1. 紧迫性：在优惠活动周围创造一种紧迫感，让人们感到必须立刻行动，以免错失机会。\n",
            "2. 独家性：让人们感到他们正在购买独特的东西，而这些东西不是每个人都可以得到的。\n",
            "3. 稀缺性：在促销活动周围创造一种稀缺感，让人们感到可用的产品数量有限。\n",
            "4. 新鲜感：强调产品或服务是新的和创新的，以及如何为人们的生活带来积极变化。\n",
            "5. 独特好处：突出产品或服务的独特好处，以及如何解决你目标受众的特定问题。\n",
            "这些只是一些你可以用于广告活动的替代概念的例子。重要的是你要了解你目标受众并能够创建一个与他们共鸣的信息。<|endoftext|>\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:00.926\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m556\u001b[0m - \u001b[34m\u001b[1mDecode labels[0]:\n",
            "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>当然。作为广告客户，我如何帮助您？您广告活动的目标是什么？您的目标受众是什么？请提供更多信息，以便我能够为您提供更有针对性的支持。<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>以下是一些你可以用于广告活动的替代概念：\n",
            "1. 紧迫性：在优惠活动周围创造一种紧迫感，让人们感到必须立刻行动，以免错失机会。\n",
            "2. 独家性：让人们感到他们正在购买独特的东西，而这些东西不是每个人都可以得到的。\n",
            "3. 稀缺性：在促销活动周围创造一种稀缺感，让人们感到可用的产品数量有限。\n",
            "4. 新鲜感：强调产品或服务是新的和创新的，以及如何为人们的生活带来积极变化。\n",
            "5. 独特好处：突出产品或服务的独特好处，以及如何解决你目标受众的特定问题。\n",
            "这些只是一些你可以用于广告活动的替代概念的例子。重要的是你要了解你目标受众并能够创建一个与他们共鸣的信息。<|endoftext|>\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:00.927\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m570\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:00.927\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m574\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'conversations': [{'from': 'human', 'value': '治疗阳痿吃什么药呢？，性生活一直很正常的，但是这段时间感觉性欲变低了，有时勃起都感觉很困难，试过许多的方法都没效果，听朋友说我这种情况可能会是早泄，想知道治疗早泄的药物？'}, {'from': 'gpt', 'value': '男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。'}]}\u001b[0m\n",
            "Running tokenizer on validation dataset: 100% 10/10 [00:00<00:00, 139.92 examples/s]\n",
            "Filter: 100% 10/10 [00:00<00:00, 1902.35 examples/s]\n",
            "\u001b[32m2025-12-23 05:21:04.624\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m584\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 10\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:04.624\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m585\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:04.625\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m586\u001b[0m - \u001b[34m\u001b[1mA chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: 治疗阳痿吃什么药呢？，性生活一直很正常的，但是这段时间感觉性欲变低了，有时勃起都感觉很困难，试过许多的方法都没效果，听朋友说我这种情况可能会是早泄，想知道治疗早泄的药物？ ASSISTANT:男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。<|endoftext|>\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:04.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m705\u001b[0m - \u001b[1m🔧 大模型训练配置:\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:04.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m706\u001b[0m - \u001b[1m  model_kwargs: {'config': Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151643,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 896,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4864,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 24,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 14,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_mrope\": false,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            ", 'torch_dtype': torch.bfloat16, 'trust_remote_code': True, 'quantization_config': None, 'low_cpu_mem_usage': True, 'device_map': 'auto'}\u001b[0m\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "\u001b[32m2025-12-23 05:21:05.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m713\u001b[0m - \u001b[1m✅ 模型加载完成\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m716\u001b[0m - \u001b[1m📊 模型分布情况:\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m718\u001b[0m - \u001b[1m🔧 使用HuggingFace设备映射:\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m720\u001b[0m - \u001b[1m  : 0\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m728\u001b[0m - \u001b[1m📈 设备使用统计:\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m730\u001b[0m - \u001b[1m  0: 1 个模块\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m751\u001b[0m - \u001b[1m💾 GPU内存使用情况:\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m756\u001b[0m - \u001b[1m  GPU 0: 已分配=0.9GB, 缓存=0.9GB, 总计=14.7GB\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m798\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m813\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m822\u001b[0m - \u001b[1mPeft target_modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m823\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
            "trainable params: 4,399,104 || all params: 498,431,872 || trainable%: 0.8826\n",
            "\u001b[32m2025-12-23 05:21:05.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m845\u001b[0m - \u001b[1mGradient checkpointing enabled.\u001b[0m\n",
            "/content/MedicalGPT/supervised_finetuning.py:862: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SavePeftModelTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = SavePeftModelTrainer(\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "\u001b[32m2025-12-23 05:21:05.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m874\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.410\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m876\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids': tensor([[    32,   6236,   1948,  ..., 151643, 151643, 151643],\n",
            "        [    32,   6236,   1948,  ...,  99898,   1773, 151643],\n",
            "        [    32,   6236,   1948,  ..., 151643, 151643, 151643],\n",
            "        [    32,   6236,   1948,  ..., 151643, 151643, 151643]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'labels': tensor([[  -100,   -100,   -100,  ...,   -100,   -100,   -100],\n",
            "        [  -100,   -100,   -100,  ...,  99898,   1773, 151643],\n",
            "        [  -100,   -100,   -100,  ...,   -100,   -100,   -100],\n",
            "        [  -100,   -100,   -100,  ...,   -100,   -100,   -100]],\n",
            "       device='cuda:0')}\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.443\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m877\u001b[0m - \u001b[34m\u001b[1minput_ids:\n",
            "[tensor([    32,   6236,   1948,    264,  22208,   1196,    323,    458,  20443,\n",
            "         11229,  17847,     13,    576,  17847,   6696,  10950,     11,  11682,\n",
            "            11,    323,  47787,  11253,    311,    279,   1196,    594,   4755,\n",
            "          3918,     82,     29,   6448,     25,  18137,    103,    101,  32108,\n",
            "         33071,  99180,  35551,  45356,  99180,  35551,  99252,   9370, 104650,\n",
            "        101899, 101895,  99245,  11319,  35560,   3846,   2821,     25,  32664,\n",
            "         99769, 100143,  54542,  24968, 120412,  99180, 101953, 101899, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643],\n",
            "       device='cuda:0'), tensor([    32,   6236,   1948,    264,  22208,   1196,    323,    458,  20443,\n",
            "         11229,  17847,     13,    576,  17847,   6696,  10950,     11,  11682,\n",
            "            11,    323,  47787,  11253,    311,    279,   1196,    594,   4755,\n",
            "          3918,     82,     29,   6448,     25,    220, 107809,  11622,  25411,\n",
            "         40814, 101454,  24339, 112672, 100625,  28404,  99678,   9370, 114091,\n",
            "        101037,  11319,  35560,   3846,   2821,     25, 103942,  73670,      0,\n",
            "         32181,    247,  20412, 100625,  28404,  99678,  26940,  77419,  38989,\n",
            "         99858,  25067,   9370, 114091,   3837,  59879,  19360,  51461,    229,\n",
            "         40814,  51463,  48443,  73594,  12669,    198,     55,     25,     16,\n",
            "           198,     51,  74045,   7679,   6222,     79,  38940,  39614,    198,\n",
            "            44,     25,     19,     14,     19,    198,     43,     25,     16,\n",
            "            14,     19,    198,     42,  69856,    198,     48,     25,     16,\n",
            "            14,     19,     28,     16,     17,     15,    198,     89,     17,\n",
            "           760,    434,     17,    434,     17,    362,     17,    272,     17,\n",
            "           760,    272,     17,    272,     17,    425,     17,    362,     17,\n",
            "           760,    479,     17,    479,     17,    479,     17,    362,     17,\n",
            "           760,    425,     17,    425,     17,    425,     17,   1147,     17,\n",
            "          9248,     66,      6,     17,    272,      6,     17,    294,      6,\n",
            "            17,    384,      6,     17,    760,    282,      6,     17,    282,\n",
            "             6,     17,    384,      6,     17,    294,      6,     17,    760,\n",
            "           272,      6,     17,    272,      6,     17,    425,     17,    362,\n",
            "            17,    760,    479,     17,    479,     17,    479,     17,   1147,\n",
            "            17,   9248,     89,     17,    760,    272,     17,    272,     17,\n",
            "           294,     17,    384,     17,    760,    282,     17,    282,     17,\n",
            "           384,     17,    294,     17,    760,    272,     17,    272,     17,\n",
            "           425,     17,    362,     17,    760,    479,     17,    479,     17,\n",
            "           479,     17,   1147,     17,   9248,     89,     17,    760,    434,\n",
            "            17,    434,     17,    362,     17,    272,     17,    760,    272,\n",
            "            17,    272,     17,    425,     17,    362,     17,    760,    479,\n",
            "            17,    479,     17,    479,     17,    362,     17,    760,    425,\n",
            "            17,    425,     17,    425,     17,   1147,     17,   9248,     66,\n",
            "             6,     17,    272,      6,     17,    294,      6,     17,    384,\n",
            "             6,     17,    760,    282,      6,     17,    282,      6,     17,\n",
            "           384,     17,    294,     17,    760,    272,      6,     17,    272,\n",
            "             6,     17,    425,     17,    362,     17,    760,    479,     17,\n",
            "           479,     17,    479,     17,   1147,     17,   9248,  13874,  19324,\n",
            "        100137,  40814, 101454,  24339, 116984,  44063, 114091,  31196,  26939,\n",
            "        100646, 103951,  74220,  15946,   3837, 101912,  99350, 101454, 103951,\n",
            "         57191, 106726,  31548,   3837, 105920, 114091,  73670,  18397,  53222,\n",
            "         57191,  23031, 101454,  20742, 100414, 102703,  99898,   1773, 151643],\n",
            "       device='cuda:0'), tensor([    32,   6236,   1948,    264,  22208,   1196,    323,    458,  20443,\n",
            "         11229,  17847,     13,    576,  17847,   6696,  10950,     11,  11682,\n",
            "            11,    323,  47787,  11253,    311,    279,   1196,    594,   4755,\n",
            "          3918,     82,     29,   6448,     25,  69372,  98749,  98237,  30534,\n",
            "        106637,  35560,   3846,   2821,     25, 106637, 101158, 101042, 108872,\n",
            "         51575, 105080,   3837, 102215,  99795, 102064,   5373, 104564, 102064,\n",
            "         99998,  20074, 100166,   3837,  71268, 101137, 100414,  72881, 102648,\n",
            "         46448,   1773, 106637, 104820,  20412,  60610,  31196,   9370, 100166,\n",
            "          3837, 102119,  17714,  99794,  68862,  31196,  57191,  99553, 102988,\n",
            "        109963,  66017,   8997, 106637,  66558, 118619,  75768,   3837, 100398,\n",
            "         37029, 104339, 108747,  96555, 106637, 106708, 102064,  33108, 109988,\n",
            "         66017,   1773, 101883, 102716, 106637,  99361, 100630,    510,      9,\n",
            "         61991,  99743, 111228, 106637,     25,    220,  75882,  39907,  45181,\n",
            "         31196,   9370, 102198, 100166,  55286,   3837, 104137, 101042, 103991,\n",
            "        108872,   8997,      9,  61991,  99413, 105798, 106637,     25,    220,\n",
            "         75882,  39907,  45181, 106506, 108872,  55286,   3837, 105798, 101042,\n",
            "        101908,  31196, 100166,   8997,      9,    220, 100520, 100040, 102008,\n",
            "        106637,     25,  32181,    247,  86402,  39907,  37029, 108940, 100520,\n",
            "        100040,  32804,  36407, 101042,  31196,   9370, 100166,   1773, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643],\n",
            "       device='cuda:0')], \n",
            "labels:\n",
            "[tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,  32664,\n",
            "         99769, 100143,  54542,  24968, 120412,  99180, 101953, 101899, 151643,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100],\n",
            "       device='cuda:0'), tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100, 103942,  73670,      0,\n",
            "         32181,    247,  20412, 100625,  28404,  99678,  26940,  77419,  38989,\n",
            "         99858,  25067,   9370, 114091,   3837,  59879,  19360,  51461,    229,\n",
            "         40814,  51463,  48443,  73594,  12669,    198,     55,     25,     16,\n",
            "           198,     51,  74045,   7679,   6222,     79,  38940,  39614,    198,\n",
            "            44,     25,     19,     14,     19,    198,     43,     25,     16,\n",
            "            14,     19,    198,     42,  69856,    198,     48,     25,     16,\n",
            "            14,     19,     28,     16,     17,     15,    198,     89,     17,\n",
            "           760,    434,     17,    434,     17,    362,     17,    272,     17,\n",
            "           760,    272,     17,    272,     17,    425,     17,    362,     17,\n",
            "           760,    479,     17,    479,     17,    479,     17,    362,     17,\n",
            "           760,    425,     17,    425,     17,    425,     17,   1147,     17,\n",
            "          9248,     66,      6,     17,    272,      6,     17,    294,      6,\n",
            "            17,    384,      6,     17,    760,    282,      6,     17,    282,\n",
            "             6,     17,    384,      6,     17,    294,      6,     17,    760,\n",
            "           272,      6,     17,    272,      6,     17,    425,     17,    362,\n",
            "            17,    760,    479,     17,    479,     17,    479,     17,   1147,\n",
            "            17,   9248,     89,     17,    760,    272,     17,    272,     17,\n",
            "           294,     17,    384,     17,    760,    282,     17,    282,     17,\n",
            "           384,     17,    294,     17,    760,    272,     17,    272,     17,\n",
            "           425,     17,    362,     17,    760,    479,     17,    479,     17,\n",
            "           479,     17,   1147,     17,   9248,     89,     17,    760,    434,\n",
            "            17,    434,     17,    362,     17,    272,     17,    760,    272,\n",
            "            17,    272,     17,    425,     17,    362,     17,    760,    479,\n",
            "            17,    479,     17,    479,     17,    362,     17,    760,    425,\n",
            "            17,    425,     17,    425,     17,   1147,     17,   9248,     66,\n",
            "             6,     17,    272,      6,     17,    294,      6,     17,    384,\n",
            "             6,     17,    760,    282,      6,     17,    282,      6,     17,\n",
            "           384,     17,    294,     17,    760,    272,      6,     17,    272,\n",
            "             6,     17,    425,     17,    362,     17,    760,    479,     17,\n",
            "           479,     17,    479,     17,   1147,     17,   9248,  13874,  19324,\n",
            "        100137,  40814, 101454,  24339, 116984,  44063, 114091,  31196,  26939,\n",
            "        100646, 103951,  74220,  15946,   3837, 101912,  99350, 101454, 103951,\n",
            "         57191, 106726,  31548,   3837, 105920, 114091,  73670,  18397,  53222,\n",
            "         57191,  23031, 101454,  20742, 100414, 102703,  99898,   1773, 151643],\n",
            "       device='cuda:0'), tensor([  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100, 106637, 101158, 101042, 108872,\n",
            "         51575, 105080,   3837, 102215,  99795, 102064,   5373, 104564, 102064,\n",
            "         99998,  20074, 100166,   3837,  71268, 101137, 100414,  72881, 102648,\n",
            "         46448,   1773, 106637, 104820,  20412,  60610,  31196,   9370, 100166,\n",
            "          3837, 102119,  17714,  99794,  68862,  31196,  57191,  99553, 102988,\n",
            "        109963,  66017,   8997, 106637,  66558, 118619,  75768,   3837, 100398,\n",
            "         37029, 104339, 108747,  96555, 106637, 106708, 102064,  33108, 109988,\n",
            "         66017,   1773, 101883, 102716, 106637,  99361, 100630,    510,      9,\n",
            "         61991,  99743, 111228, 106637,     25,    220,  75882,  39907,  45181,\n",
            "         31196,   9370, 102198, 100166,  55286,   3837, 104137, 101042, 103991,\n",
            "        108872,   8997,      9,  61991,  99413, 105798, 106637,     25,    220,\n",
            "         75882,  39907,  45181, 106506, 108872,  55286,   3837, 105798, 101042,\n",
            "        101908,  31196, 100166,   8997,      9,    220, 100520, 100040, 102008,\n",
            "        106637,     25,  32181,    247,  86402,  39907,  37029, 108940, 100520,\n",
            "        100040,  32804,  36407, 101042,  31196,   9370, 100166,   1773, 151643,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
            "          -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100],\n",
            "       device='cuda:0')]\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.493\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m878\u001b[0m - \u001b[34m\u001b[1mDecode input_ids[0]:\n",
            "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: 骨化性气管支气管病的辅助治疗有些什么？ ASSISTANT:对症支持处理；氩气刀治疗<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\u001b[0m\n",
            "\u001b[32m2025-12-23 05:21:05.542\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m881\u001b[0m - \u001b[34m\u001b[1mDecode labels[0]:\n",
            "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>对症支持处理；氩气刀治疗<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\u001b[0m\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 151643}.\n",
            "{'loss': 2.5827, 'grad_norm': 1.3944993019104004, 'learning_rate': 0.0, 'epoch': 0.0}\n",
            "{'loss': 2.609, 'grad_norm': 1.0852948427200317, 'learning_rate': 1.3846153846153847e-05, 'epoch': 0.04}\n",
            "{'loss': 2.7038, 'grad_norm': 1.549014687538147, 'learning_rate': 1.949367088607595e-05, 'epoch': 0.08}\n",
            "{'loss': 2.471, 'grad_norm': 1.0538694858551025, 'learning_rate': 1.8649789029535868e-05, 'epoch': 0.12}\n",
            "{'loss': 2.3965, 'grad_norm': 1.3449335098266602, 'learning_rate': 1.780590717299578e-05, 'epoch': 0.16}\n",
            "{'loss': 2.5249, 'grad_norm': 1.253195881843567, 'learning_rate': 1.6962025316455696e-05, 'epoch': 0.2}\n",
            " 20% 50/250 [02:08<09:58,  2.99s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:00<00:00,  2.59it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 3.152466297149658, 'eval_runtime': 2.108, 'eval_samples_per_second': 4.744, 'eval_steps_per_second': 1.423, 'epoch': 0.2}\n",
            " 20% 50/250 [02:10<09:58,  2.99s/it]\n",
            "100% 3/3 [00:01<00:00,  1.78it/s]\u001b[A\n",
            "{'loss': 2.5123, 'grad_norm': 1.7407509088516235, 'learning_rate': 1.6118143459915612e-05, 'epoch': 0.24}\n",
            "{'loss': 2.5918, 'grad_norm': 1.2133322954177856, 'learning_rate': 1.5274261603375528e-05, 'epoch': 0.28}\n",
            "{'loss': 2.508, 'grad_norm': 1.4401912689208984, 'learning_rate': 1.4430379746835444e-05, 'epoch': 0.32}\n",
            "{'loss': 2.319, 'grad_norm': 1.1382466554641724, 'learning_rate': 1.358649789029536e-05, 'epoch': 0.36}\n",
            "{'loss': 2.3522, 'grad_norm': 1.7073585987091064, 'learning_rate': 1.2742616033755275e-05, 'epoch': 0.4}\n",
            " 40% 100/250 [04:27<07:09,  2.86s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:00<00:00,  2.59it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.1033942699432373, 'eval_runtime': 2.1043, 'eval_samples_per_second': 4.752, 'eval_steps_per_second': 1.426, 'epoch': 0.4}\n",
            " 40% 100/250 [04:29<07:09,  2.86s/it]\n",
            "100% 3/3 [00:01<00:00,  1.78it/s]\u001b[A\n",
            "{'loss': 2.283, 'grad_norm': 1.9501125812530518, 'learning_rate': 1.189873417721519e-05, 'epoch': 0.44}\n",
            "{'loss': 2.6048, 'grad_norm': 1.5854929685592651, 'learning_rate': 1.1054852320675107e-05, 'epoch': 0.48}\n",
            "{'loss': 2.272, 'grad_norm': 2.0303213596343994, 'learning_rate': 1.0210970464135021e-05, 'epoch': 0.52}\n",
            "{'loss': 2.2889, 'grad_norm': 2.0720577239990234, 'learning_rate': 9.367088607594937e-06, 'epoch': 0.56}\n",
            "{'loss': 2.2359, 'grad_norm': 1.4198884963989258, 'learning_rate': 8.523206751054853e-06, 'epoch': 0.6}\n",
            " 60% 150/250 [06:40<03:58,  2.38s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:00<00:00,  2.59it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.0911412239074707, 'eval_runtime': 2.1254, 'eval_samples_per_second': 4.705, 'eval_steps_per_second': 1.412, 'epoch': 0.6}\n",
            " 60% 150/250 [06:42<03:58,  2.38s/it]\n",
            "100% 3/3 [00:01<00:00,  1.77it/s]\u001b[A\n",
            "{'loss': 2.4231, 'grad_norm': 1.4711718559265137, 'learning_rate': 7.679324894514768e-06, 'epoch': 0.64}\n",
            "{'loss': 2.1647, 'grad_norm': 1.1103184223175049, 'learning_rate': 6.835443037974684e-06, 'epoch': 0.68}\n",
            "{'loss': 2.345, 'grad_norm': 1.1370669603347778, 'learning_rate': 5.9915611814346e-06, 'epoch': 0.72}\n",
            "{'loss': 2.154, 'grad_norm': 1.1209746599197388, 'learning_rate': 5.147679324894516e-06, 'epoch': 0.76}\n",
            "{'loss': 2.3489, 'grad_norm': 1.4529430866241455, 'learning_rate': 4.303797468354431e-06, 'epoch': 0.8}\n",
            " 80% 200/250 [09:01<02:18,  2.77s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:00<00:00,  2.59it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.085050106048584, 'eval_runtime': 2.1108, 'eval_samples_per_second': 4.737, 'eval_steps_per_second': 1.421, 'epoch': 0.8}\n",
            " 80% 200/250 [09:03<02:18,  2.77s/it]\n",
            "100% 3/3 [00:01<00:00,  1.78it/s]\u001b[A\n",
            "{'loss': 2.3683, 'grad_norm': 1.7766014337539673, 'learning_rate': 3.459915611814346e-06, 'epoch': 0.84}\n",
            "{'loss': 2.497, 'grad_norm': 1.364638090133667, 'learning_rate': 2.6160337552742622e-06, 'epoch': 0.88}\n",
            "{'loss': 2.6105, 'grad_norm': 2.2798120975494385, 'learning_rate': 1.7721518987341774e-06, 'epoch': 0.92}\n",
            "{'loss': 2.3138, 'grad_norm': 1.303694248199463, 'learning_rate': 9.28270042194093e-07, 'epoch': 0.96}\n",
            "{'loss': 2.4783, 'grad_norm': 1.9348341226577759, 'learning_rate': 8.438818565400844e-08, 'epoch': 1.0}\n",
            "100% 250/250 [11:19<00:00,  2.30s/it]\n",
            "  0% 0/3 [00:00<?, ?it/s]\u001b[A\n",
            " 67% 2/3 [00:00<00:00,  2.60it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 3.0836503505706787, 'eval_runtime': 2.1091, 'eval_samples_per_second': 4.741, 'eval_steps_per_second': 1.422, 'epoch': 1.0}\n",
            "100% 250/250 [11:21<00:00,  2.30s/it]\n",
            "100% 3/3 [00:01<00:00,  1.78it/s]\u001b[A\n",
            "{'train_runtime': 681.9673, 'train_samples_per_second': 1.463, 'train_steps_per_second': 0.367, 'train_loss': 2.4149569931030275, 'epoch': 1.0}\n",
            "100% 250/250 [11:21<00:00,  2.73s/it]\n",
            "***** train metrics *****\n",
            "  epoch                    =        1.0\n",
            "  total_flos               =   878597GF\n",
            "  train_loss               =      2.415\n",
            "  train_runtime            = 0:11:21.96\n",
            "  train_samples            =       1000\n",
            "  train_samples_per_second =      1.463\n",
            "  train_steps_per_second   =      0.367\n",
            "\u001b[32m2025-12-23 05:32:27.941\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m898\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 681.9673, 'train_samples_per_second': 1.463, 'train_steps_per_second': 0.367, 'total_flos': 943387169931264.0, 'train_loss': 2.4149569931030275, 'epoch': 1.0, 'train_samples': 1000}\u001b[0m\n",
            "\u001b[32m2025-12-23 05:32:27.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m899\u001b[0m - \u001b[1mSaving model checkpoint to outputs-sft-v1\u001b[0m\n",
            "\u001b[32m2025-12-23 05:32:28.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m908\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
            "100% 3/3 [00:01<00:00,  1.66it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        1.0\n",
            "  eval_loss               =     3.0833\n",
            "  eval_runtime            = 0:00:02.05\n",
            "  eval_samples            =         10\n",
            "  eval_samples_per_second =      4.869\n",
            "  eval_steps_per_second   =      1.461\n",
            "  perplexity              =    21.8307\n",
            "\u001b[32m2025-12-23 05:32:30.539\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m921\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 3.0833163261413574, 'eval_runtime': 2.0537, 'eval_samples_per_second': 4.869, 'eval_steps_per_second': 1.461, 'epoch': 1.0, 'eval_samples': 10, 'perplexity': 21.830680136895566}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python supervised_finetuning.py \\\n",
        "    --model_name_or_path merged-pt \\\n",
        "    --train_file_dir ./data/finetune \\\n",
        "    --validation_file_dir ./data/finetune \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --use_peft True \\\n",
        "    --bf16 \\\n",
        "    --max_train_samples 1000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.05 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --eval_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --preprocessing_num_workers 1 \\\n",
        "    --output_dir outputs-sft-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype bfloat16 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --gradient_checkpointing True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BPcRS02xHkWM",
        "outputId": "d3603833-e409-40c6-f165-8900c5fe2daa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 22M\n",
            "-rw-r--r-- 1 root root 1.1K Dec 23 05:32 adapter_config.json\n",
            "-rw-r--r-- 1 root root  17M Dec 23 05:32 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root  605 Dec 23 05:32 added_tokens.json\n",
            "-rw-r--r-- 1 root root  430 Dec 23 05:32 all_results.json\n",
            "-rw-r--r-- 1 root root 2.4K Dec 23 05:32 chat_template.jinja\n",
            "drwxr-xr-x 2 root root 4.0K Dec 23 05:32 \u001b[0m\u001b[01;34mcheckpoint-250\u001b[0m/\n",
            "-rw-r--r-- 1 root root  221 Dec 23 05:32 eval_results.json\n",
            "-rw-r--r-- 1 root root 1.6M Dec 23 05:32 merges.txt\n",
            "-rw-r--r-- 1 root root 5.1K Dec 23 05:32 README.md\n",
            "drwxr-xr-x 3 root root 4.0K Dec 23 05:21 \u001b[01;34mruns\u001b[0m/\n",
            "-rw-r--r-- 1 root root  648 Dec 23 05:32 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 4.7K Dec 23 05:32 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root 6.0K Dec 23 05:32 trainer_state.json\n",
            "-rw-r--r-- 1 root root  229 Dec 23 05:32 train_results.json\n",
            "-rw-r--r-- 1 root root 3.3M Dec 23 05:32 vocab.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-sft-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "chxDx5qqHkWM"
      },
      "source": [
        "模型训练结果：\n",
        "- 使用lora训练模型，则保存的lora权重是`adapter_model.safetensors`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
        "- 日志保存在`output_dir/runs`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "JXMST4vZHkWM"
      },
      "source": [
        "lora模型权重合并到base model，合并后的模型保存在`--output_dir`目录下，合并方法如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6nxsYUdCHkWM",
        "outputId": "797efc8c-1546-4d6f-f2c1-b874fe017bce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-23 05:34:19.242958: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766468059.263257   11125 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766468059.269321   11125 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766468059.284689   11125 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766468059.284722   11125 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766468059.284730   11125 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766468059.284733   11125 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-23 05:34:19.289351: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(base_model='merged-pt', tokenizer_path=None, lora_model='outputs-sft-v1', resize_emb=False, output_dir='merged-sft/', hf_hub_model_id='', hf_hub_token=None)\n",
            "Base model: merged-pt\n",
            "LoRA model: outputs-sft-v1\n",
            "Loading LoRA for causal language model\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "The tokenizer you are loading from 'merged-pt' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
            "Merging with merge_and_unload...\n",
            "Saving to Hugging Face format...\n",
            "Done! model saved to merged-sft/\n"
          ]
        }
      ],
      "source": [
        "!python merge_peft_adapter.py \\\n",
        "    --base_model merged-pt --lora_model outputs-sft-v1 --output_dir merged-sft/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OmTZb62aHkWN",
        "outputId": "01f02759-9ad0-4d07-d402-b0422394cf52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 958M\n",
            "-rw-r--r-- 1 root root  605 Dec 23 05:34 added_tokens.json\n",
            "-rw-r--r-- 1 root root 2.4K Dec 23 05:34 chat_template.jinja\n",
            "-rw-r--r-- 1 root root 1.3K Dec 23 05:34 config.json\n",
            "-rw-r--r-- 1 root root  117 Dec 23 05:34 generation_config.json\n",
            "-rw-r--r-- 1 root root 1.6M Dec 23 05:34 merges.txt\n",
            "-rw-r--r-- 1 root root 943M Dec 23 05:34 model.safetensors\n",
            "-rw-r--r-- 1 root root  616 Dec 23 05:34 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 4.6K Dec 23 05:34 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  11M Dec 23 05:34 tokenizer.json\n",
            "-rw-r--r-- 1 root root 2.7M Dec 23 05:34 vocab.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh merged-sft/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1IJjtiCQHkWN",
        "outputId": "c0d8a27d-bd18-4a01-a9f4-97404f980cc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151643,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 896,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4864,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 24,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 14,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_mrope\": false,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%cat merged-sft/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "9UhfSveBHkWN"
      },
      "source": [
        "Stage2 SFT训练完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T14:07:40.752635Z",
          "start_time": "2023-06-15T14:07:40.731186Z"
        },
        "id": "Orc7NrvWHkWN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "T5GmTFpDHkWN"
      },
      "source": [
        "# Stage 3: Reward Modeling\n",
        "\n",
        "第三阶段：RM(Reward Model)奖励模型建模，构造人类偏好排序数据集，训练奖励模型，用来对齐人类偏好，主要是\"HHH\"原则，具体是\"helpful, honest, harmless\"\n",
        "\n",
        "| Stage 3: Reward Modeling        |  [reward_modeling.py](https://github.com/shibing624/MedicalGPT/blob/main/reward_modeling.py) | [run_rm.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_rm.sh)    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Kd2POdNuHkWN"
      },
      "source": [
        "#### 说明：\n",
        "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
        "\n",
        "1. 生成模型：使用的是Qwen/Qwen2.5-0.5B 或者 Stage2得到的SFT模型\n",
        "2. 数据集：RM阶段使用的是医疗reward数据，抽样了500条，位于`data/reward`文件夹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "gQjMM88UHkWN"
      },
      "source": [
        "## Stage3 咱们开始吧\n",
        "\n",
        "训练步骤如下：\n",
        "\n",
        "1. 确认训练集\n",
        "2. 执行训练脚本\n",
        "\n",
        "训练脚本的执行逻辑如下：\n",
        "1. 导入依赖包\n",
        "2. 设置参数\n",
        "3. 定义各函数并加载训练集\n",
        "4. 加载模型和tokenizer\n",
        "5. 开始训练并评估\n",
        "6. 查看训练结果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-mJvQP4yHkWN",
        "outputId": "57504e3e-f10f-406b-e619-b529269705ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dpo_zh_500.jsonl\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/reward/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "t52S-wQBHkWN",
        "outputId": "793e2b7f-c0f4-4d9b-e3e1-8dbc6ed27009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-23 05:35:24.835184: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766468124.874660   11418 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766468124.886410   11418 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766468124.914210   11418 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766468124.914250   11418 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766468124.914254   11418 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766468124.914258   11418 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-23 05:35:24.921641: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[32m2025-12-23 05:35:30.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m332\u001b[0m - \u001b[1mModel args: ModelArguments(model_name_or_path='merged-sft', tokenizer_name_or_path=None, load_in_4bit=False, load_in_8bit=False, cache_dir=None, use_fast_tokenizer=False, torch_dtype='float16', device_map='auto', trust_remote_code=True)\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:30.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m333\u001b[0m - \u001b[1mData args: DataArguments(dataset_name=None, dataset_config_name=None, train_file_dir='./data/reward', validation_file_dir='./data/reward', max_source_length=256, max_target_length=256, max_train_samples=1000, max_eval_samples=10, overwrite_cache=False, validation_split_percentage=1, preprocessing_num_workers=4)\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:30.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m334\u001b[0m - \u001b[1mTraining args: TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=False,\n",
            "ddp_timeout=30000,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=50,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-rm-v1/runs/Dec23_05-35-30_7bb3e7c60fab,\n",
            "logging_first_step=True,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs-rm-v1,\n",
            "overwrite_output_dir=True,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=1,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=3,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "use_cpu=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.05,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.001,\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:30.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mScript args: ScriptArguments(use_peft=True, target_modules='all', lora_rank=8, lora_dropout=0.05, lora_alpha=16.0, modules_to_save=None, peft_path=None, template_name='vicuna')\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:30.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mProcess rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: True\u001b[0m\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at merged-sft and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2025-12-23 05:35:31.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m391\u001b[0m - \u001b[1mAdd bos_token: <|endoftext|>, bos_token_id: 151643\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:31.678\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m398\u001b[0m - \u001b[34m\u001b[1mTokenizer: Qwen2Tokenizer(name_or_path='merged-sft', vocab_size=151643, model_max_length=131072, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "}\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:31.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m401\u001b[0m - \u001b[1mFine-tuning method: LoRA(PEFT)\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:31.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m406\u001b[0m - \u001b[1mInit new peft model\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:31.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m415\u001b[0m - \u001b[1mPeft target_modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:31.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m416\u001b[0m - \u001b[1mPeft lora_rank: 8\u001b[0m\n",
            "trainable params: 4,400,000 || all params: 498,433,664 || trainable%: 0.8828\n",
            "\u001b[32m2025-12-23 05:35:31.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m459\u001b[0m - \u001b[1mtrain files: ./data/reward/dpo_zh_500.jsonl\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:31.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m464\u001b[0m - \u001b[1meval files: ./data/reward/dpo_zh_500.jsonl\u001b[0m\n",
            "Generating train split: 500 examples [00:00, 20584.33 examples/s]\n",
            "Generating validation split: 500 examples [00:00, 71963.21 examples/s]\n",
            "\u001b[32m2025-12-23 05:35:32.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m485\u001b[0m - \u001b[1mRaw datasets: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['system', 'history', 'question', 'response_chosen', 'response_rejected'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['system', 'history', 'question', 'response_chosen', 'response_rejected'],\n",
            "        num_rows: 500\n",
            "    })\n",
            "})\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:32.242\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m533\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'system': '', 'history': [], 'question': '20个关于新鲜果汁菜单的口号，适用于一家名为\"Dishes\"的餐厅', 'response_chosen': '这里是一个名为“Dishes”的餐厅的20个口号，突出了其新鲜果汁菜单：\\n\\n1. “品尝Dishes新鲜果汁，感受不同！”\\n2. “新鲜榨取，直达您的餐桌 - Dishes果汁纯享！”\\n3. “用一杯清新的Dishes果汁开启您的一天！”\\n4. “每一口Dishes新鲜果汁都是大自然的味道！”\\n5. “Dishes：新鲜果汁是焦点！”\\n6. “满足您的口腹之欲，享用Dishes口水直流的农场果汁！”\\n7. “新鲜果汁，新鲜味道，新鲜菜肴 - 这是Dishes的承诺！”\\n8. “用Dishes营养果汁获得每日所需的维生素和矿物质！”\\n9. “解渴滋养心灵，品尝Dishes美味果汁！”\\n10. “Dishes：每一口都是完美的味道！”\\n11. “新鲜制作，完美平衡 - Dishes果汁是感官的享受！”\\n12. “从农场到餐桌，Dishes果汁充满天然好处！”\\n13. “踏入Dishes，品尝我们新鲜果汁的甜蜜！”\\n14. “用Dishes 100%新鲜水果果汁呵护您的身体！”\\n15. “Dishes：每一杯果汁都是用激情和关怀精心制作！”\\n16. “沉醉于Dishes新鲜榨取果汁的健康热情！”\\n17. “用Dishes招牌果汁混合物提升您的用餐体验！”\\n18. “健康饮品的清新转变 - Dishes果汁必尝！”\\n19. “加入Dishes的新鲜果汁革命 - 您的味蕾会感激您！”\\n20. “Dishes：果汁永远新鲜，味道永远美味！”', 'response_rejected': '1. \"与菜肴一起品尝新鲜！\"\\n2. \"菜肴：新鲜果汁，新的开始！\"\\n3. \"用菜肴的新鲜混合果汁提神！\"\\n4. \"菜肴，新鲜就是最好的\"\\n5. \"在菜肴庆祝新鲜\"\\n6. \"与菜肴的新鲜果汁为健康干杯\"\\n7. \"在菜肴发现新鲜的魔力\"\\n8. \"品尝菜肴的新鲜果汁，感受不同\"\\n9. \"在菜肴解锁新鲜\"\\n10. \"用菜肴的新鲜果汁迎接新的一天\"\\n11. \"在菜肴，每天都有新鲜\"\\n12. \"用菜肴的新鲜果汁获得能量\"\\n13. \"在菜肴为生活喝果汁\"\\n14. \"拥抱健康，享受菜肴的新鲜果汁\"\\n15. \"菜肴：新鲜与美味的交汇处\"\\n16. \"在菜肴体验新鲜的力量\"\\n17. \"菜肴：把健康送到你家门口\"\\n18. \"像微风一样清新，菜肴的果汁\"\\n19. \"生命太短暂，只为菜肴的新鲜果汁\"\\n20. \"菜肴：新鲜始终是你一天的首选\"'}\u001b[0m\n",
            "Running tokenizer on dataset (num_proc=4): 100% 500/500 [00:22<00:00, 22.59 examples/s]\n",
            "Filter: 100% 500/500 [00:00<00:00, 1735.94 examples/s]\n",
            "\u001b[32m2025-12-23 05:35:57.363\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m547\u001b[0m - \u001b[34m\u001b[1mNum train_samples: 339\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:57.363\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m548\u001b[0m - \u001b[34m\u001b[1mTokenized training example:\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:57.364\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m549\u001b[0m - \u001b[34m\u001b[1mA chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: 我希望你能扮演一个专家的角色。你对于旅行规划的所有信息了如指掌。我会就旅行规划中的不同主题向你提问，你需要给我清晰、简洁和准确的信息。请确保你回答问题时充满自信。 \n",
            "\n",
            "主题 = 旅行规划 ASSISTANT:当然！我在这里可以帮助您解答任何关于旅行规划的问题。请随意问我任何与这个话题相关的问题，我会为您提供清晰、简洁和准确的信息。我会以礼貌、乐于助人和尊重的方式来帮助您，同时确保我的回答不包含任何有害或不道德的内容。\n",
            "您有关于旅行规划的具体问题吗？也许您正在寻找去哪里、如何规划行程或到达目的地后该做什么的建议？无论您有什么问题，请不要犹豫，我会尽力帮助您。\u001b[0m\n",
            "\u001b[32m2025-12-23 05:35:57.366\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m562\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'system': '', 'history': [], 'question': '20个关于新鲜果汁菜单的口号，适用于一家名为\"Dishes\"的餐厅', 'response_chosen': '这里是一个名为“Dishes”的餐厅的20个口号，突出了其新鲜果汁菜单：\\n\\n1. “品尝Dishes新鲜果汁，感受不同！”\\n2. “新鲜榨取，直达您的餐桌 - Dishes果汁纯享！”\\n3. “用一杯清新的Dishes果汁开启您的一天！”\\n4. “每一口Dishes新鲜果汁都是大自然的味道！”\\n5. “Dishes：新鲜果汁是焦点！”\\n6. “满足您的口腹之欲，享用Dishes口水直流的农场果汁！”\\n7. “新鲜果汁，新鲜味道，新鲜菜肴 - 这是Dishes的承诺！”\\n8. “用Dishes营养果汁获得每日所需的维生素和矿物质！”\\n9. “解渴滋养心灵，品尝Dishes美味果汁！”\\n10. “Dishes：每一口都是完美的味道！”\\n11. “新鲜制作，完美平衡 - Dishes果汁是感官的享受！”\\n12. “从农场到餐桌，Dishes果汁充满天然好处！”\\n13. “踏入Dishes，品尝我们新鲜果汁的甜蜜！”\\n14. “用Dishes 100%新鲜水果果汁呵护您的身体！”\\n15. “Dishes：每一杯果汁都是用激情和关怀精心制作！”\\n16. “沉醉于Dishes新鲜榨取果汁的健康热情！”\\n17. “用Dishes招牌果汁混合物提升您的用餐体验！”\\n18. “健康饮品的清新转变 - Dishes果汁必尝！”\\n19. “加入Dishes的新鲜果汁革命 - 您的味蕾会感激您！”\\n20. “Dishes：果汁永远新鲜，味道永远美味！”', 'response_rejected': '1. \"与菜肴一起品尝新鲜！\"\\n2. \"菜肴：新鲜果汁，新的开始！\"\\n3. \"用菜肴的新鲜混合果汁提神！\"\\n4. \"菜肴，新鲜就是最好的\"\\n5. \"在菜肴庆祝新鲜\"\\n6. \"与菜肴的新鲜果汁为健康干杯\"\\n7. \"在菜肴发现新鲜的魔力\"\\n8. \"品尝菜肴的新鲜果汁，感受不同\"\\n9. \"在菜肴解锁新鲜\"\\n10. \"用菜肴的新鲜果汁迎接新的一天\"\\n11. \"在菜肴，每天都有新鲜\"\\n12. \"用菜肴的新鲜果汁获得能量\"\\n13. \"在菜肴为生活喝果汁\"\\n14. \"拥抱健康，享受菜肴的新鲜果汁\"\\n15. \"菜肴：新鲜与美味的交汇处\"\\n16. \"在菜肴体验新鲜的力量\"\\n17. \"菜肴：把健康送到你家门口\"\\n18. \"像微风一样清新，菜肴的果汁\"\\n19. \"生命太短暂，只为菜肴的新鲜果汁\"\\n20. \"菜肴：新鲜始终是你一天的首选\"'}\u001b[0m\n",
            "Running tokenizer on dataset (num_proc=4): 100% 10/10 [00:10<00:00,  1.03s/ examples]\n",
            "Filter: 100% 10/10 [00:00<00:00, 792.08 examples/s]\n",
            "\u001b[32m2025-12-23 05:36:10.375\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m575\u001b[0m - \u001b[34m\u001b[1mNum eval_samples: 5\u001b[0m\n",
            "\u001b[32m2025-12-23 05:36:10.375\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m576\u001b[0m - \u001b[34m\u001b[1mTokenized eval example:\u001b[0m\n",
            "\u001b[32m2025-12-23 05:36:10.377\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m577\u001b[0m - \u001b[34m\u001b[1mA chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.</s>USER: 20个关于新鲜果汁菜单的口号，适用于一家名为\"Dishes\"的餐厅 ASSISTANT:这里是一个名为“Dishes”的餐厅的20个口号，突出了其新鲜果汁菜单：\n",
            "\n",
            "1. “品尝Dishes新鲜果汁，感受不同！”\n",
            "2. “新鲜榨取，直达您的餐桌 - Dishes果汁纯享！”\n",
            "3. “用一杯清新的Dishes果汁开启您的一天！”\n",
            "4. “每一口Dishes新鲜果汁都是大自然的味道！”\n",
            "5. “Dishes：新鲜果汁是焦点！”\n",
            "6. “满足您的口腹之欲，享用Dishes口水直流的农场果汁！”\n",
            "7. “新鲜果汁，新鲜味道，新鲜菜肴 - 这是Dishes的承诺！”\n",
            "8. “用Dishes营养果汁获得每日所需的维生素和矿物质！”\n",
            "9. “解渴滋养心灵，品尝Dishes美味果汁！”\n",
            "10. “Dishes：每一口都是完美的味道！”\n",
            "11. “新鲜制作，完美平衡 - Dishes果汁是感官的享受！”\n",
            "12. “从农场到餐桌，Dishes果汁充满天然好处！”\n",
            "13. “踏入Dishes，品尝我们新鲜果汁的甜蜜！”\n",
            "14. “用Dishes 100%新鲜水果果汁呵护您的身体！”\n",
            "15. “Dishes：每一杯果汁都是用激情和关怀精心制作！”\n",
            "16. “沉醉于Dishes新鲜榨取果汁的健康热情！”\n",
            "17. “用Dishes招牌果汁混合物提升您的用餐体验！”\n",
            "18. “健康饮品的清新转变 - Dishes果汁必尝！”\n",
            "19. “加入Dishes的新鲜果汁革命 - 您的味蕾会感激您！”\n",
            "20. “Dishes：果汁永远新鲜，味道永远美味！”\u001b[0m\n",
            "/content/MedicalGPT/reward_modeling.py:590: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `RewardTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = RewardTrainer(\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "\u001b[32m2025-12-23 05:36:10.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m604\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "\u001b[32m2025-12-23 05:36:10.470\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m605\u001b[0m - \u001b[34m\u001b[1mTrain dataloader example: {'input_ids_chosen': tensor([[ 56568, 101909,  15469, 106575,   1773,  99553, 109648, 102349,   3837,\n",
            "          32555,  20002, 104689,  18493, 105413,  78973, 104077, 101128, 102349,\n",
            "          37132,     82,     29,   6448,     25,  38903,    228, 100697, 101038,\n",
            "          46944, 101339, 109784,   3837,  99517,  99461,  80443,  99428,  34187,\n",
            "           3837,  99360,  99927,  99945, 104132, 102182,  69249, 108804, 105950,\n",
            "           1773,  62244,  56007,   2073, 100584, 100697, 103922,  36993, 104139,\n",
            "         100681,  11319,  33590,   2073, 105750,    854, 101909, 104775, 102349,\n",
            "         101037,  94432, 102349,  20412,   5122,  35560,   3846,   2821,     25,\n",
            "         101068,  60610,   2183,   6130, 103922,  36993, 104139, 100535, 101224,\n",
            "           3837,  99519,  99605, 108876,  33108, 101128, 104309, 115742,   1773,\n",
            "         103968,  96050, 100137, 104705,  41505, 105750,    854,  87267, 102095,\n",
            "          32664,   2183,   6130, 101224,  31235, 102188,   9370,  53481,   1773,\n",
            "         106124,   3837,   2183,   6130, 104309,  99519, 100364, 101106, 104028,\n",
            "         104056,  87140,  99329, 101904,  68536, 104048, 112321,   5373, 118009,\n",
            "          57191,  18830, 112321,  63109,   1773, 105750, 108063, 102119, 109228,\n",
            "          32664,  99569,  17340, 109955,  99539, 100271,  33108, 100765,  96050,\n",
            "         100137, 104705,  87267, 104605, 101073,   3837, 104033,  62244,   2183,\n",
            "           6130, 100684, 100690, 100720,  99487, 101339,   1773, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]],\n",
            "       device='cuda:0'), 'attention_mask_chosen': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'input_ids_rejected': tensor([[ 56568, 101909,  15469, 106575,   1773,  99553, 109648, 102349,   3837,\n",
            "          32555,  20002, 104689,  18493, 105413,  78973, 104077, 101128, 102349,\n",
            "          37132,     82,     29,   6448,     25,  38903,    228, 100697, 101038,\n",
            "          46944, 101339, 109784,   3837,  99517,  99461,  80443,  99428,  34187,\n",
            "           3837,  99360,  99927,  99945, 104132, 102182,  69249, 108804, 105950,\n",
            "           1773,  62244,  56007,   2073, 100584, 100697, 103922,  36993, 104139,\n",
            "         100681,  11319,  33590,   2073, 105750,    854, 101909, 104775, 102349,\n",
            "         101037,  94432, 102349,  20412,   5122,  35560,   3846,   2821,     25,\n",
            "         100345, 103008,  27369,   3837,   2183,   6130, 101038, 101339,  99366,\n",
            "          87140,  99329,  62926,  99360,  99927,  99945, 114871, 102182, 100622,\n",
            "         105950,  33447,   3837, 102342,  87267, 100394, 105750, 104336,   1773,\n",
            "          99917, 104506,  48443,     16,     13,  84238,    118, 100467, 102193,\n",
            "          27369,   5122, 108024,  15946, 105283, 110329, 102406,   2183,   6130,\n",
            "          33108, 101339, 110117, 109977, 104612,  57191,  99605,  72064,   1773,\n",
            "          80443, 100656, 104754,  57191, 100656, 110257,   3837,   2183,   6130,\n",
            "         102342,  87267,  44063, 101339, 104796, 105257,  17714, 105750,   8997,\n",
            "             17,     13,  90476,    100,  62922, 108140,   5122, 102630,  99519,\n",
            "          46944, 102015, 101038,  46944, 101989,  99366,  87140,  99329,  62926,\n",
            "         100669,  99927,  99945, 100622, 105950,  68536, 100394, 105750, 102222,\n",
            "         105424, 101158, 109391, 108140,   3837, 103980,  34187, 101063, 105106,\n",
            "          33108, 101968,   9370, 108589,  99483,  87531, 101507,   8997,     18,\n",
            "             13,  84238,    118, 100467, 117072,   5122, 101339,  18493,  57218,\n",
            "           2183,   6130,   9370, 104199,  15946,  80443, 107837,  99885, 117072,\n",
            "          57191, 108465,  33071,   1773,  99517, 100009,  18493,  99366,  87140,\n",
            "          99329,  62926, 100669,  99927,  99945, 100622, 105950,   3837,  43288,\n",
            "         100684, 102406,  99517,  18830, 105750, 110257,  57191, 111450,   8997,\n",
            "             19,     13,  86009, 112449,   9370, 102193,   5122,  99329,  99928,\n",
            "          20412, 100659,  85336, 109784,  33108,  57218,  99614, 102470,   9370,\n",
            "         117262,   1773, 108019, 105750, 104199,   9370, 102618, 102325,   3837,\n",
            "           2183,   6130, 102342,  87267, 108939, 104705,  44063, 101339, 104796,\n",
            "         105257,  17714, 105750,   3407, 101886,  41505, 105750,    854,  99520,\n",
            "           2183,   6130, 103922,  36993,  99996, 101224, 107474, 102349,   1773,\n",
            "          46944,  33126, 106873, 102349, 104560,   2073, 102962,    854,  57191,\n",
            "           2073, 103198,  33590,  99519,   2183,   6130,  87267,  32664,  99794,\n",
            "         101339, 105628, 101139,  33108, 100565, 103198,   1773, 101948,   3837,\n",
            "           2183,   6130,  87267, 100009, 109136, 101339, 100669, 100648,  99927,\n",
            "          99945, 100622, 105950,   9370, 118009,  33108, 115457,   1773, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
            "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]],\n",
            "       device='cuda:0'), 'attention_mask_rejected': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'return_loss': True}\u001b[0m\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 151643}.\n",
            "  0% 0/339 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
            "{'loss': 1.8671, 'grad_norm': nan, 'learning_rate': 0.0, 'epoch': 0.0}\n",
            "{'loss': 1.9266, 'grad_norm': nan, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.03}\n",
            "{'loss': 2.6832, 'grad_norm': 103.84041595458984, 'learning_rate': 1.9875776397515528e-05, 'epoch': 0.06}\n",
            "{'loss': 1.5008, 'grad_norm': 15.212916374206543, 'learning_rate': 1.925465838509317e-05, 'epoch': 0.09}\n",
            "{'loss': 1.2161, 'grad_norm': 62.494728088378906, 'learning_rate': 1.863354037267081e-05, 'epoch': 0.12}\n",
            "{'loss': 1.3759, 'grad_norm': 180.8528594970703, 'learning_rate': 1.801242236024845e-05, 'epoch': 0.15}\n",
            " 15% 50/339 [00:33<03:03,  1.58it/s]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:00, 11.20it/s]\u001b[A\n",
            " 80% 4/5 [00:00<00:00,  6.93it/s]\u001b[A\n",
            "                                    \n",
            "\u001b[A{'eval_loss': 0.9289745092391968, 'eval_mse': 1.7492653131484985, 'eval_mae': 1.216796875, 'eval_runtime': 0.9787, 'eval_samples_per_second': 5.109, 'eval_steps_per_second': 5.109, 'epoch': 0.15}\n",
            " 15% 50/339 [00:34<03:03,  1.58it/s]\n",
            "100% 5/5 [00:00<00:00,  6.36it/s]\u001b[A\n",
            "{'loss': 1.1549, 'grad_norm': 0.5067713856697083, 'learning_rate': 1.739130434782609e-05, 'epoch': 0.18}\n",
            "{'loss': 2.644, 'grad_norm': 77.39837646484375, 'learning_rate': 1.6770186335403728e-05, 'epoch': 0.21}\n",
            "{'loss': 1.0623, 'grad_norm': 121.25214385986328, 'learning_rate': 1.6149068322981367e-05, 'epoch': 0.24}\n",
            "{'loss': 0.9837, 'grad_norm': 85.13391876220703, 'learning_rate': 1.5527950310559007e-05, 'epoch': 0.27}\n",
            "{'loss': 0.871, 'grad_norm': 175.422119140625, 'learning_rate': 1.4906832298136646e-05, 'epoch': 0.29}\n",
            " 29% 100/339 [01:06<02:28,  1.61it/s]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:00, 11.27it/s]\u001b[A\n",
            " 80% 4/5 [00:00<00:00,  6.83it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.8670133352279663, 'eval_mse': 1.8860695362091064, 'eval_mae': 1.316796898841858, 'eval_runtime': 0.928, 'eval_samples_per_second': 5.388, 'eval_steps_per_second': 5.388, 'epoch': 0.29}\n",
            " 29% 100/339 [01:07<02:28,  1.61it/s]\n",
            "100% 5/5 [00:00<00:00,  6.43it/s]\u001b[A\n",
            "{'loss': 1.0673, 'grad_norm': 60.182823181152344, 'learning_rate': 1.4285714285714287e-05, 'epoch': 0.32}\n",
            "{'loss': 1.3135, 'grad_norm': 118.70547485351562, 'learning_rate': 1.3664596273291926e-05, 'epoch': 0.35}\n",
            "{'loss': 1.479, 'grad_norm': 125.531982421875, 'learning_rate': 1.3043478260869566e-05, 'epoch': 0.38}\n",
            "{'loss': 0.995, 'grad_norm': 92.91222381591797, 'learning_rate': 1.2422360248447205e-05, 'epoch': 0.41}\n",
            "{'loss': 1.2356, 'grad_norm': 108.78926086425781, 'learning_rate': 1.1801242236024846e-05, 'epoch': 0.44}\n",
            " 44% 150/339 [01:39<02:05,  1.51it/s]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:00, 10.86it/s]\u001b[A\n",
            " 80% 4/5 [00:00<00:00,  7.05it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.5525881052017212, 'eval_mse': 1.3410186767578125, 'eval_mae': 1.0710937976837158, 'eval_runtime': 0.9116, 'eval_samples_per_second': 5.485, 'eval_steps_per_second': 5.485, 'epoch': 0.44}\n",
            " 44% 150/339 [01:40<02:05,  1.51it/s]\n",
            "100% 5/5 [00:00<00:00,  6.65it/s]\u001b[A\n",
            "{'loss': 1.7917, 'grad_norm': 37.816749572753906, 'learning_rate': 1.1180124223602484e-05, 'epoch': 0.47}\n",
            "{'loss': 0.9022, 'grad_norm': 73.41455078125, 'learning_rate': 1.0559006211180125e-05, 'epoch': 0.5}\n",
            "{'loss': 1.8589, 'grad_norm': 35.94327926635742, 'learning_rate': 9.937888198757764e-06, 'epoch': 0.53}\n",
            "{'loss': 1.1792, 'grad_norm': 27.503704071044922, 'learning_rate': 9.316770186335405e-06, 'epoch': 0.56}\n",
            "{'loss': 0.6958, 'grad_norm': 65.54021453857422, 'learning_rate': 8.695652173913044e-06, 'epoch': 0.59}\n",
            " 59% 200/339 [02:12<01:33,  1.49it/s]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:00,  9.05it/s]\u001b[A\n",
            " 60% 3/5 [00:00<00:00,  5.55it/s]\u001b[A\n",
            " 80% 4/5 [00:00<00:00,  4.66it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.5234060287475586, 'eval_mse': 1.7969634532928467, 'eval_mae': 1.1789062023162842, 'eval_runtime': 1.2507, 'eval_samples_per_second': 3.998, 'eval_steps_per_second': 3.998, 'epoch': 0.59}\n",
            " 59% 200/339 [02:13<01:33,  1.49it/s]\n",
            "100% 5/5 [00:01<00:00,  4.51it/s]\u001b[A\n",
            "{'loss': 1.3796, 'grad_norm': 100.35090637207031, 'learning_rate': 8.074534161490684e-06, 'epoch': 0.62}\n",
            "{'loss': 0.7491, 'grad_norm': 15.687045097351074, 'learning_rate': 7.453416149068323e-06, 'epoch': 0.65}\n",
            "{'loss': 1.4609, 'grad_norm': 107.22444915771484, 'learning_rate': 6.832298136645963e-06, 'epoch': 0.68}\n",
            "{'loss': 2.6092, 'grad_norm': 22.788423538208008, 'learning_rate': 6.2111801242236025e-06, 'epoch': 0.71}\n",
            "{'loss': 1.9521, 'grad_norm': 37.930355072021484, 'learning_rate': 5.590062111801242e-06, 'epoch': 0.74}\n",
            " 74% 250/339 [02:45<00:57,  1.55it/s]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:00, 11.03it/s]\u001b[A\n",
            " 80% 4/5 [00:00<00:00,  7.04it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.491790235042572, 'eval_mse': 2.3286170959472656, 'eval_mae': 1.2527344226837158, 'eval_runtime': 0.9182, 'eval_samples_per_second': 5.446, 'eval_steps_per_second': 5.446, 'epoch': 0.74}\n",
            " 74% 250/339 [02:46<00:57,  1.55it/s]\n",
            "100% 5/5 [00:00<00:00,  6.48it/s]\u001b[A\n",
            "{'loss': 1.0082, 'grad_norm': 124.5327377319336, 'learning_rate': 4.968944099378882e-06, 'epoch': 0.77}\n",
            "{'loss': 1.4786, 'grad_norm': 21.543235778808594, 'learning_rate': 4.347826086956522e-06, 'epoch': 0.8}\n",
            "{'loss': 2.08, 'grad_norm': 0.3314210772514343, 'learning_rate': 3.7267080745341615e-06, 'epoch': 0.83}\n",
            "{'loss': 1.2151, 'grad_norm': 71.46990203857422, 'learning_rate': 3.1055900621118013e-06, 'epoch': 0.86}\n",
            "{'loss': 0.941, 'grad_norm': 5.026252746582031, 'learning_rate': 2.484472049689441e-06, 'epoch': 0.88}\n",
            " 88% 300/339 [03:18<00:24,  1.60it/s]\n",
            "  0% 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 40% 2/5 [00:00<00:00, 11.11it/s]\u001b[A\n",
            " 80% 4/5 [00:00<00:00,  7.13it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.5159618854522705, 'eval_mse': 2.4134345054626465, 'eval_mae': 1.2878906726837158, 'eval_runtime': 0.9457, 'eval_samples_per_second': 5.287, 'eval_steps_per_second': 5.287, 'epoch': 0.88}\n",
            " 88% 300/339 [03:19<00:24,  1.60it/s]\n",
            "100% 5/5 [00:00<00:00,  6.47it/s]\u001b[A\n",
            "{'loss': 1.3283, 'grad_norm': 0.23843784630298615, 'learning_rate': 1.8633540372670808e-06, 'epoch': 0.91}\n",
            "{'loss': 1.4455, 'grad_norm': 7.120169639587402, 'learning_rate': 1.2422360248447205e-06, 'epoch': 0.94}\n",
            "{'loss': 1.7274, 'grad_norm': 0.09957735240459442, 'learning_rate': 6.211180124223603e-07, 'epoch': 0.97}\n",
            "{'train_runtime': 224.9032, 'train_samples_per_second': 1.507, 'train_steps_per_second': 1.507, 'train_loss': 1.423853452226757, 'epoch': 1.0}\n",
            "100% 339/339 [03:44<00:00,  1.51it/s]\n",
            "***** train metrics *****\n",
            "  epoch                    =        1.0\n",
            "  total_flos               =        0GF\n",
            "  train_loss               =     1.4239\n",
            "  train_runtime            = 0:03:44.90\n",
            "  train_samples            =        500\n",
            "  train_samples_per_second =      1.507\n",
            "  train_steps_per_second   =      1.507\n",
            "\u001b[32m2025-12-23 05:39:55.914\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m619\u001b[0m - \u001b[34m\u001b[1mTraining metrics: {'train_runtime': 224.9032, 'train_samples_per_second': 1.507, 'train_steps_per_second': 1.507, 'total_flos': 0.0, 'train_loss': 1.423853452226757, 'epoch': 1.0, 'train_samples': 500}\u001b[0m\n",
            "\u001b[32m2025-12-23 05:39:55.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m620\u001b[0m - \u001b[1mSaving model checkpoint to outputs-rm-v1\u001b[0m\n",
            "\u001b[32m2025-12-23 05:39:56.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m625\u001b[0m - \u001b[1m*** Evaluate ***\u001b[0m\n",
            "100% 5/5 [00:00<00:00,  6.65it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        1.0\n",
            "  eval_loss               =     0.5087\n",
            "  eval_mae                =      1.309\n",
            "  eval_mse                =     2.4938\n",
            "  eval_runtime            = 0:00:00.94\n",
            "  eval_samples            =         10\n",
            "  eval_samples_per_second =      5.298\n",
            "  eval_steps_per_second   =      5.298\n",
            "  perplexity              =     1.6631\n",
            "\u001b[32m2025-12-23 05:39:57.340\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m637\u001b[0m - \u001b[34m\u001b[1mEval metrics: {'eval_loss': 0.5086883306503296, 'eval_mse': 2.493824005126953, 'eval_mae': 1.308984398841858, 'eval_runtime': 0.9437, 'eval_samples_per_second': 5.298, 'eval_steps_per_second': 5.298, 'epoch': 1.0, 'eval_samples': 10, 'perplexity': 1.6631083154482313}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python reward_modeling.py \\\n",
        "    --model_name_or_path merged-sft \\\n",
        "    --train_file_dir ./data/reward \\\n",
        "    --validation_file_dir ./data/reward \\\n",
        "    --per_device_train_batch_size 1 \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --do_train \\\n",
        "    --use_peft True \\\n",
        "    --seed 42 \\\n",
        "    --max_train_samples 1000 \\\n",
        "    --max_eval_samples 10 \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --warmup_ratio 0.05 \\\n",
        "    --weight_decay 0.001 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --eval_steps 50 \\\n",
        "    --eval_strategy steps \\\n",
        "    --save_steps 500 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_total_limit 3 \\\n",
        "    --max_source_length 256 \\\n",
        "    --max_target_length 256 \\\n",
        "    --output_dir outputs-rm-v1 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --ddp_timeout 30000 \\\n",
        "    --logging_first_step True \\\n",
        "    --target_modules all \\\n",
        "    --lora_rank 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --torch_dtype float16 \\\n",
        "    --fp16 \\\n",
        "    --device_map auto \\\n",
        "    --report_to tensorboard \\\n",
        "    --ddp_find_unused_parameters False \\\n",
        "    --remove_unused_columns False \\\n",
        "    --gradient_checkpointing True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "86JL2FPrHkWN",
        "outputId": "04918a35-f3a5-4db6-f9e7-ba1e36658330",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 22M\n",
            "-rw-r--r-- 1 root root 1.1K Dec 23 05:39 adapter_config.json\n",
            "-rw-r--r-- 1 root root  17M Dec 23 05:39 adapter_model.safetensors\n",
            "-rw-r--r-- 1 root root  605 Dec 23 05:39 added_tokens.json\n",
            "-rw-r--r-- 1 root root  484 Dec 23 05:39 all_results.json\n",
            "-rw-r--r-- 1 root root 2.4K Dec 23 05:39 chat_template.jinja\n",
            "drwxr-xr-x 2 root root 4.0K Dec 23 05:39 \u001b[0m\u001b[01;34mcheckpoint-339\u001b[0m/\n",
            "-rw-r--r-- 1 root root  291 Dec 23 05:39 eval_results.json\n",
            "-rw-r--r-- 1 root root 1.6M Dec 23 05:39 merges.txt\n",
            "-rw-r--r-- 1 root root 5.1K Dec 23 05:39 README.md\n",
            "drwxr-xr-x 3 root root 4.0K Dec 23 05:36 \u001b[01;34mruns\u001b[0m/\n",
            "-rw-r--r-- 1 root root  648 Dec 23 05:39 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 4.6K Dec 23 05:39 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root 8.4K Dec 23 05:39 trainer_state.json\n",
            "-rw-r--r-- 1 root root  213 Dec 23 05:39 train_results.json\n",
            "-rw-r--r-- 1 root root 3.3M Dec 23 05:39 vocab.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh outputs-rm-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "R95z1n8uHkWN"
      },
      "source": [
        "模型训练结果：\n",
        "- 使用lora训练模型，则保存的lora权重是`adapter_model.safetensors`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
        "- 日志保存在`output_dir/runs`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/runs --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "xjRrIbUrHkWN"
      },
      "source": [
        "lora模型权重合并到base model，合并后的模型保存在`--output_dir`目录下，合并方法如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "U_1Ji7vgHkWN",
        "outputId": "6941e185-987b-4864-c193-613c58e0b696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-23 05:42:47.052192: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766468567.085106   13372 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766468567.093194   13372 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766468567.117168   13372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766468567.117207   13372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766468567.117215   13372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766468567.117221   13372 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-23 05:42:47.124213: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(base_model='merged-sft', tokenizer_path=None, lora_model='outputs-rm-v1', resize_emb=False, output_dir='merged-rm/', hf_hub_model_id='', hf_hub_token=None)\n",
            "Base model: merged-sft\n",
            "LoRA model: outputs-rm-v1\n",
            "Loading LoRA for sequence classification model\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at merged-sft and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The tokenizer you are loading from 'merged-sft' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
            "Merging with merge_and_unload...\n",
            "Saving to Hugging Face format...\n",
            "Done! model saved to merged-rm/\n"
          ]
        }
      ],
      "source": [
        "!python merge_peft_adapter.py \\\n",
        "    --base_model merged-sft --lora_model outputs-rm-v1 --output_dir merged-rm/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_ziEb9eEHkWN",
        "outputId": "3e05ea0a-3073-412a-cc3c-ae238900cad1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.9G\n",
            "-rw-r--r-- 1 root root  605 Dec 23 05:42 added_tokens.json\n",
            "-rw-r--r-- 1 root root 2.4K Dec 23 05:42 chat_template.jinja\n",
            "-rw-r--r-- 1 root root 1.4K Dec 23 05:42 config.json\n",
            "-rw-r--r-- 1 root root 1.6M Dec 23 05:42 merges.txt\n",
            "-rw-r--r-- 1 root root 1.9G Dec 23 05:43 model.safetensors\n",
            "-rw-r--r-- 1 root root  616 Dec 23 05:42 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root 4.6K Dec 23 05:42 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root  11M Dec 23 05:42 tokenizer.json\n",
            "-rw-r--r-- 1 root root 2.7M Dec 23 05:42 vocab.json\n"
          ]
        }
      ],
      "source": [
        "%ls -lh merged-rm/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NZAiiYeZHkWW",
        "outputId": "ef564072-68c3-416f-c375-29c791f42c4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"float32\",\n",
            "  \"eos_token_id\": 151643,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 896,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4864,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 24,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 14,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_mrope\": false,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%cat merged-rm/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "DJzbEOohHkWW"
      },
      "source": [
        "Stage3 奖励建模第一次训练完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-15T14:12:09.472414Z",
          "start_time": "2023-06-15T14:12:09.464881Z"
        },
        "id": "6z0LbPB4HkWX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "MIkBnYTFHkWX"
      },
      "source": [
        "# Stage 4: Reinforcement Learning Training\n",
        "\n",
        "第四阶段：RL(Reinforcement Learning)基于人类反馈的强化学习(RLHF)，用奖励模型来训练SFT模型，生成模型使用奖励或惩罚来更新其策略，以便生成更高质量、更符合人类偏好的文本\n",
        "\n",
        "| Stage 4: Reinforcement Learning |  [rl_training.py](https://github.com/shibing624/MedicalGPT/blob/main/rl_training.py) | [run_rl.sh](https://github.com/shibing624/MedicalGPT/blob/main/run_rl.sh)    |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "337hG273HkWX"
      },
      "source": [
        "#### 说明：\n",
        "以下 notebook/colab 代码为了快速验证训练代码可用，我们使用了小size的生成模型、奖励模型和小样本数据集，实际使用时，需要使用更大的模型和数据集，以获得更好的效果。\n",
        "\n",
        "1. 生成模型：使用的是Qwen/Qwen2.5-0.5B 或者 Stage2得到的SFT模型\n",
        "2. 奖励模型：使用的是`OpenAssistant/reward-model-deberta-v3-large-v2` 或者 Stage3得到的BERT类或者GPT类奖励模型\n",
        "3. 数据集：RL阶段的数据可以复用SFT的数据集，使用的是Belle的1千条抽样数据，位于`data/finetune`文件夹"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "R4lvr1HCHkWX"
      },
      "source": [
        "## Stage4 咱们开始吧\n",
        "\n",
        "训练步骤如下：\n",
        "\n",
        "1. 确认训练集\n",
        "2. 执行训练脚本\n",
        "\n",
        "训练脚本的执行逻辑如下：\n",
        "1. 导入依赖包\n",
        "2. 设置参数\n",
        "3. 定义各函数并加载训练集\n",
        "4. 加载生成模型和tokenizer，加载奖励模型和其tokenizer\n",
        "5. 开始训练并评估\n",
        "6. 查看训练结果\n",
        "\n",
        "以下参数可以根据你的GPU实际情况修改，当前参数是根据Colab的T4单卡GPU（16GB显存）配置的。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wyL2ULU5HkWX",
        "outputId": "ea753924-62d6-4c40-a09b-5c56aa9d1d77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "medical_sft_1K_format.jsonl            sharegpt_zh_1K_format.jsonl\n",
            "numina_cot_sharegpt_data_1k.jsonl.bak\n"
          ]
        }
      ],
      "source": [
        "%ls ./data/finetune/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "12N-AyBDHkWX",
        "outputId": "6b8aa116-73a0-45f4-cb39-3b115f39ce9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-23 05:44:01.831689: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766468641.852003   13697 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766468641.858027   13697 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766468641.873377   13697 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766468641.873429   13697 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766468641.873433   13697 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766468641.873437   13697 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-23 05:44:01.878070: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "<string>:167: FutureWarning: The `PPOConfig` is now located in `trl.experimental`. Please update your imports to `from trl.experimental.ppo import PPOConfig`. The current import path will be removed and no longer supported in TRL 0.29. For more information, see https://github.com/huggingface/trl/issues/4223.\n",
            "<string>:24: FutureWarning: `torch_dtype` is deprecated and will be removed in version 0.27.0, please use `dtype` instead.\n",
            "\u001b[32m2025-12-23 05:44:10.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m56\u001b[0m - \u001b[1mParse args: PPOArguments(dataset_name=None, dataset_config=None, dataset_train_split='train', dataset_test_split='test', train_file_dir='./data/finetune', validation_file_dir='./data/finetune', template_name='qwen', max_source_length=256)\u001b[0m\n",
            "\u001b[32m2025-12-23 05:44:10.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m57\u001b[0m - \u001b[1mTraining args: PPOConfig(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "batch_size=None,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "cliprange=0.2,\n",
            "cliprange_value=0.2,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "dataset_num_proc=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "ds3_gather_for_generation=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "exp_name=ppo_config,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gamma=1.0,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "kl_coef=0.05,\n",
            "kl_estimator=k1,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "lam=0.95,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=False,\n",
            "local_batch_size=None,\n",
            "local_mini_batch_size=None,\n",
            "local_rank=0,\n",
            "local_rollout_forward_batch_size=1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=outputs-ppo-v1/runs/Dec23_05-44-10_7bb3e7c60fab,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=10,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs=None,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "micro_batch_size=1,\n",
            "mini_batch_size=1,\n",
            "missing_eos_penalty=None,\n",
            "model_adapter_name=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_mini_batches=1,\n",
            "num_ppo_epochs=4,\n",
            "num_sample_generations=10,\n",
            "num_total_batches=None,\n",
            "num_train_epochs=1.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=outputs-ppo-v1,\n",
            "overwrite_output_dir=False,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "ref_adapter_name=None,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "response_length=64,\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "reward_model_path=./merged-rm,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=50,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sft_model_path=./merged-sft,\n",
            "skip_memory_metrics=True,\n",
            "stop_token=<STOP_TOKEN>,\n",
            "stop_token_id=None,\n",
            "temperature=0.7,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "total_episodes=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "use_cpu=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "vf_coef=0.1,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "whiten_rewards=False,\n",
            "world_size=None,\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-12-23 05:44:10.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1mModel args: ModelConfig(model_name_or_path=None, model_revision='main', dtype='float16', trust_remote_code=False, attn_implementation=None, use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_target_parameters=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', use_rslora=False, use_dora=False, load_in_8bit=True, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False, bnb_4bit_quant_storage=None, torch_dtype='float16')\u001b[0m\n",
            "The tokenizer you are loading from './merged-sft' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
            "\u001b[32m2025-12-23 05:44:11.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mAdd bos_token: <|endoftext|>, bos_token_id: 151643\u001b[0m\n",
            "\u001b[32m2025-12-23 05:44:11.298\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m78\u001b[0m - \u001b[34m\u001b[1mTokenizer: Qwen2TokenizerFast(name_or_path='./merged-sft', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "}\n",
            ")\u001b[0m\n",
            "\u001b[32m2025-12-23 05:44:13.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m116\u001b[0m - \u001b[1mtrain files: ./data/finetune/medical_sft_1K_format.jsonl, ./data/finetune/sharegpt_zh_1K_format.jsonl\u001b[0m\n",
            "\u001b[32m2025-12-23 05:44:13.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1meval files: ./data/finetune/medical_sft_1K_format.jsonl, ./data/finetune/sharegpt_zh_1K_format.jsonl\u001b[0m\n",
            "\u001b[32m2025-12-23 05:44:14.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mGet datasets: Dataset({\n",
            "    features: ['conversations'],\n",
            "    num_rows: 2000\n",
            "}), Dataset({\n",
            "    features: ['conversations'],\n",
            "    num_rows: 100\n",
            "})\u001b[0m\n",
            "\u001b[32m2025-12-23 05:44:14.196\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m175\u001b[0m - \u001b[34m\u001b[1mExample train_dataset[0]: {'conversations': [{'from': 'human', 'value': '治疗阳痿吃什么药呢？，性生活一直很正常的，但是这段时间感觉性欲变低了，有时勃起都感觉很困难，试过许多的方法都没效果，听朋友说我这种情况可能会是早泄，想知道治疗早泄的药物？'}, {'from': 'gpt', 'value': '男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。'}]}\u001b[0m\n",
            "Running tokenizer on dataset: 100% 2000/2000 [00:01<00:00, 1791.34 examples/s]\n",
            "Filter: 100% 5351/5351 [00:00<00:00, 43641.90 examples/s]\n",
            "\u001b[32m2025-12-23 05:44:15.563\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m187\u001b[0m - \u001b[34m\u001b[1mTrain samples tokenized top3: {'input_ids': [[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 271, 151644, 872, 198, 101899, 82075, 121275, 114725, 99471, 101036, 11319, 3837, 33071, 99424, 99725, 99165, 107257, 3837, 100131, 110673, 100681, 33071, 101188, 74040, 99285, 34187, 3837, 104685, 100618, 71618, 71268, 100681, 99165, 103985, 3837, 41321, 38182, 100694, 104339, 105562, 101062, 3837, 49187, 99614, 108967, 106334, 104309, 20412, 99391, 101719, 3837, 109623, 101899, 99391, 101719, 9370, 104459, 11319, 151645, 198, 151644, 77091, 198], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 271, 151644, 872, 198, 110397, 100037, 100687, 92032, 105014, 3837, 100447, 99744, 101891, 102187, 3837, 114606, 3837, 110397, 100037, 100687, 92032, 105014, 3837, 100447, 99744, 101891, 102187, 3837, 114606, 3837, 85106, 106428, 101071, 151645, 198, 151644, 77091, 198], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 271, 151644, 872, 198, 116594, 43959, 101940, 9370, 113422, 102021, 11319, 151645, 198, 151644, 77091, 198]]}\u001b[0m\n",
            "\u001b[32m2025-12-23 05:44:15.563\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m190\u001b[0m - \u001b[34m\u001b[1mExample eval_dataset[0]: {'conversations': [{'from': 'human', 'value': '治疗阳痿吃什么药呢？，性生活一直很正常的，但是这段时间感觉性欲变低了，有时勃起都感觉很困难，试过许多的方法都没效果，听朋友说我这种情况可能会是早泄，想知道治疗早泄的药物？'}, {'from': 'gpt', 'value': '男子早泄、早泄病症的再次发生，多由恣情纵欲，或青年误犯性交，至命门火衰，精气虚寒；或思量忧郁，伤损心脾；或因恐惧伤肾，也有因湿热下注，宗筋弛而痿的。但主要是肾阳虚衰而痿。肾阳为那身阳气之根本，有温煦形体，蒸化水液，增进围产生长发育等功能。肾阳虚衰则温煦失责，气化无权。因而再次发生畏寒肢冷，性机能减退。故见男子早泄不举或不坚，且伴发头晕目眩。'}]}\u001b[0m\n",
            "Running tokenizer on dataset: 100% 100/100 [00:00<00:00, 3806.43 examples/s]\n",
            "Filter: 100% 100/100 [00:00<00:00, 21477.31 examples/s]\n",
            "\u001b[32m2025-12-23 05:44:15.711\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m202\u001b[0m - \u001b[34m\u001b[1mEval samples tokenized top3: {'input_ids': [[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 271, 151644, 872, 198, 101899, 82075, 121275, 114725, 99471, 101036, 11319, 3837, 33071, 99424, 99725, 99165, 107257, 3837, 100131, 110673, 100681, 33071, 101188, 74040, 99285, 34187, 3837, 104685, 100618, 71618, 71268, 100681, 99165, 103985, 3837, 41321, 38182, 100694, 104339, 105562, 101062, 3837, 49187, 99614, 108967, 106334, 104309, 20412, 99391, 101719, 3837, 109623, 101899, 99391, 101719, 9370, 104459, 11319, 151645, 198, 151644, 77091, 198], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 271, 151644, 872, 198, 110397, 100037, 100687, 92032, 105014, 3837, 100447, 99744, 101891, 102187, 3837, 114606, 3837, 110397, 100037, 100687, 92032, 105014, 3837, 100447, 99744, 101891, 102187, 3837, 114606, 3837, 85106, 106428, 101071, 151645, 198, 151644, 77091, 198], [151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 271, 151644, 872, 198, 116594, 43959, 101940, 9370, 113422, 102021, 11319, 151645, 198, 151644, 77091, 198]]}\u001b[0m\n",
            "/content/MedicalGPT/ppo_training.py:205: FutureWarning: The `PPOTrainer` is now located in `trl.experimental`. Please update your imports to `from trl.experimental.ppo import PPOTrainer`. The current import path will be removed and no longer supported in TRL 0.29. For more information, see https://github.com/huggingface/trl/issues/4223.\n",
            "  trainer = PPOTrainer(\n",
            "\u001b[32m2025-12-23 05:44:25.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m220\u001b[0m - \u001b[1m*** Train ***\u001b[0m\n",
            "===training policy===\n",
            "  0% 0/5351 [00:00<?, ?it/s]`generation_config` default values have been modified to match model-specific defaults: {'bos_token_id': 151643}. If this is not desired, please set these values explicitly.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/MedicalGPT/ppo_training.py\", line 231, in <module>\n",
            "    main()\n",
            "  File \"/content/MedicalGPT/ppo_training.py\", line 221, in main\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/trl/experimental/ppo/ppo_trainer.py\", line 670, in train\n",
            "    optimizer.step()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/optimizer.py\", line 166, in step\n",
            "    self.scaler.step(self.optimizer, closure)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\", line 448, in step\n",
            "    retval = optimizer.step(*args, **kwargs_)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/optimizer.py\", line 211, in patched_step\n",
            "    return method(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py\", line 133, in wrapper\n",
            "    return func.__get__(opt, opt.__class__)(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\", line 517, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\", line 82, in _use_grad\n",
            "    ret = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\", line 237, in step\n",
            "    has_complex = self._init_group(\n",
            "                  ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\", line 177, in _init_group\n",
            "    state[\"exp_avg\"] = torch.zeros_like(\n",
            "                       ^^^^^^^^^^^^^^^^^\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 2.12 MiB is free. Process 139638 has 14.74 GiB memory in use. Of the allocated memory 14.31 GiB is allocated by PyTorch, and 297.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "  0% 0/5351 [00:04<?, ?it/s]\n",
            "[W1223 05:44:31.587944728 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())\n"
          ]
        }
      ],
      "source": [
        "! PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True CUDA_VISIBLE_DEVICES=0 python ppo_training.py \\\n",
        "  --sft_model_path ./merged-sft \\\n",
        "  --reward_model_path ./merged-rm \\\n",
        "  --template_name qwen \\\n",
        "  --torch_dtype float16 \\\n",
        "  --fp16 True \\\n",
        "  --load_in_8bit True \\\n",
        "  --train_file_dir ./data/finetune \\\n",
        "  --validation_file_dir ./data/finetune \\\n",
        "  --max_source_length 256 \\\n",
        "  --response_length 64 \\\n",
        "  --do_train \\\n",
        "  --num_train_epochs 1 \\\n",
        "  --save_steps 50 \\\n",
        "  --output_dir outputs-ppo-v1 \\\n",
        "  --per_device_train_batch_size 1 \\\n",
        "  --local_rollout_forward_batch_size 1 \\\n",
        "  --micro_batch_size 1 \\\n",
        "  --mini_batch_size 1 \\\n",
        "  --gradient_checkpointing True \\\n",
        "  --load_in_8bit True \\\n",
        "  --report_to tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BW_TyHsHkWX"
      },
      "outputs": [],
      "source": [
        "%ls -lh outputs-ppo-v1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "0axvJa2UHkWX"
      },
      "source": [
        "模型训练结果：\n",
        "- use_peft=False,默认是使用全参训练，模型保存的就是`model-00001-of-00002.safetensors`等文件，配置文件是`config.json`\n",
        "- use_peft=True, 则使用lora训练模型，则保存的lora权重是`adapter_model.safetensors`, lora配置文件是`adapter_config.json`，合并到base model的方法见`merge_peft_adapter.py`\n",
        "- 日志保存在`output_dir/trl`目录下，可以使用tensorboard查看，启动tensorboard方式如下：`tensorboard --logdir output_dir/trl --host 0.0.0.0 --port 8009`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI12f4YUHkWX"
      },
      "outputs": [],
      "source": [
        "%ls -lh outputs-ppo-v1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tmx_6ysjHkWX"
      },
      "outputs": [],
      "source": [
        "%cat outputs-ppo-v1/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "FEM06t_dHkWX"
      },
      "source": [
        "Stage4 RL第一次训练完成。\n",
        "\n",
        "**至此一个完整的4阶段训练流程演示完成。**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "6lo3KHWTHkWX"
      },
      "source": [
        "实际操作中Stage3和Stage4可以反复多次，直到RL得到的最后模型满足评估要求。\n",
        "\n",
        "RLHF过程可以把SFT模型当成一个初始化模型，RM模型当做指导老师，使用RL(PPO)调教SFT模型生成指导老师最满意的结果，如果小学老师满意了，我们就再训练一个中学老师，继续指导，中学老师满意了，就训练一个大学老师，这样不断迭代，使得生成模型的质量达到甚至超过人工撰写的天花板。\n",
        "\n",
        "RLHF训练不易，此项目提供给大家一种实现的方法和参考，希望抛砖引玉，共同促进中文开源LLM发展。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "n7VY-XooHkWX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-26T12:34:29.658428Z",
          "start_time": "2023-06-26T12:34:29.620609Z"
        },
        "id": "oQ3HGfyoHkWX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "6IJ7fvafHkWX"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "RQcsu76NHkWX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-06-26T12:35:00.864463Z",
          "start_time": "2023-06-26T12:34:47.802087Z"
        },
        "id": "1ma-yIx3HkWX"
      },
      "outputs": [],
      "source": [
        "!python inference.py --base_model merged-ppo-v1\n",
        "# 或在shell中运行\n",
        "# !python inference.py --base_model merged-ppo-v1 --interactive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5H0AvJgpHkWX"
      },
      "source": [
        "Input:介绍下南京\n",
        "Response:  南京市位于江苏省西南部，是全国首批历史文化名城、国家中心城市和自由贸易试验区。\n",
        "\n",
        "完。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l30y3F2HkWX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f34eed0bebedfc4b6ee51ced43d2c030fe3b92f13c149d072205ca200a67b1ec"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}